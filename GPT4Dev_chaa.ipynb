{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnathan2012/Programming-iOS-Book-Examples/blob/master/GPT4Dev_chaa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0ujXQ_NIzTu"
      },
      "source": [
        "# ChatGPT 開發實戰\n",
        "\n",
        "這是旗標科技《ChatGPT 開發實戰》新版本搭配 Azure OpenAI API 的範例檔案。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在建立資源時, 請選 sweden central, 會有最[多種的模型](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)可以選用。"
      ],
      "metadata": {
        "id": "G8bIvQmba3LD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a42M4mg1qNQ5"
      },
      "source": [
        "## 使用 Python 呼叫 API\n",
        "\n",
        "OpenAI 官方提供有 openai 套件, 可以簡化直接使用 requests 模組的複雜度。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQrw-pWsth0b"
      },
      "source": [
        "### 使用官方 openai 套件"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwGTl75BLNwu"
      },
      "source": [
        "#### 安裝與使用 openai **套件**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9x1F86C4T9u"
      },
      "outputs": [],
      "source": [
        "!pip install gradio rich tiktoken openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXBIuei0zDQB"
      },
      "source": [
        "### 在 Colab 設定機密資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-X8C602xf2J"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import json\n",
        "import base64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Duh4SCmLh7a"
      },
      "source": [
        "### 使用 Azure OpenAI API\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IgF-6qzLhje"
      },
      "outputs": [],
      "source": [
        "from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdFV7NvKLoEU"
      },
      "source": [
        "### 建立 Azure OpenAI API 用戶端"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_2uHTPYOsgU"
      },
      "source": [
        "以下各參數請參考 Playground 裡面顯示程式碼的部分, 這裡的 endpoint 是 Playground 裡面的 api_base。\n",
        "\n",
        "- api_version 請參考[這裡](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning)\n",
        "- endpoint 請參考[這裡](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPszMBfDMIat"
      },
      "outputs": [],
      "source": [
        "client = AzureOpenAI(\n",
        "    api_version='2023-07-01-preview',\n",
        "    # api_version='2023-12-01-preview',\n",
        "    azure_endpoint='https://f4762-api.openai.azure.com/',\n",
        "    api_key=userdata.get('AZURE_OPENAI_KEY')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_8Ngm9QLvyQ"
      },
      "source": [
        "### 測試 Chat Completions API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si-FTVTKNGty"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model='gpt41106', # 佈署名稱\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"你好\",\n",
        "        },\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyelatvvLiIn"
      },
      "source": [
        "檢視傳回物件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8C3ImwKD5a5"
      },
      "outputs": [],
      "source": [
        "print(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSjownHrGnde"
      },
      "outputs": [],
      "source": [
        "from rich import print as pprint\n",
        "pprint(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDHvn0VCGPzH"
      },
      "outputs": [],
      "source": [
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev4TvoQ3ps-z"
      },
      "source": [
        "#### 直接使用模組叫用 API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvomwkY3pwNx"
      },
      "outputs": [],
      "source": [
        "# Azure OpenAI 似乎不能這樣用\n",
        "import openai\n",
        "openai.api_key = userdata.get('AZURE_OPENAI_KEY')\n",
        "openai.api_version='2023-07-01-preview',\n",
        "openai.azure_endpoint='https://swedencentralflag.openai.azure.com/',\n",
        "\n",
        "reply = openai.chat.completions.create(\n",
        "    model='gpt351106', # 佈署名稱\n",
        "    # model = \"gpt-4\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"你好\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joNfGjzFJb5q"
      },
      "outputs": [],
      "source": [
        "pprint(reply)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXM-kBtH2f5B"
      },
      "source": [
        "#### 轉成 Python 字典"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihiXl36g1z-u"
      },
      "outputs": [],
      "source": [
        "pprint(reply.model_dump())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP5FkDxALp4e"
      },
      "source": [
        "#### 傳遞多筆訊息"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1x0glPsNJe2"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt351106\",\n",
        "    messages = [\n",
        "        {\"role\":\"system\", \"content\":\"你是條住在深海、只會台灣中文的魚\"},\n",
        "        {\"role\":\"user\", \"content\": \"你住的地方很亮嗎？\"}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48eLL4VEQGza"
      },
      "outputs": [],
      "source": [
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65D0ie-qt8_d"
      },
      "source": [
        "## 認識 token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1BO-OuaFW0f"
      },
      "source": [
        "### token 切割視覺化工具\n",
        "\n",
        "官方的[切割工具](https://platform.openai.com/encoder.encode)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z-Ab0R2Kg4V"
      },
      "source": [
        "### 使用 tiktoken 套件計算精確 token 數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L98OeqzKjJVm"
      },
      "outputs": [],
      "source": [
        "# !pip install tiktoken\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZxDdv76jrvO"
      },
      "outputs": [],
      "source": [
        "encoder = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
        "print(encoder.name)\n",
        "encoder = tiktoken.encoding_for_model('gpt-4')\n",
        "print(encoder.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8SFWn0HHtsp"
      },
      "outputs": [],
      "source": [
        "tokens = encoder.encode(\"你好\")\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oChT24mGmKcZ"
      },
      "outputs": [],
      "source": [
        "print(encoder.decode(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pqpu0XGMDcD"
      },
      "source": [
        "### ChatML 標記語言"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWDiULI-My-x"
      },
      "outputs": [],
      "source": [
        "print(encoder.encode(\"user\"))\n",
        "print(encoder.encode(\"assistant\"))\n",
        "print(encoder.encode(\"system\"))\n",
        "print(encoder.encode(\"\\n\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp8Dlbd8MNPL"
      },
      "source": [
        "計算 message 總 tokens 數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTMcDBnLuz4Z"
      },
      "outputs": [],
      "source": [
        "def tokens_in_messages(messages):\n",
        "    totals = 0\n",
        "    for message in messages:\n",
        "        for k in message:\n",
        "            if k == \"content\":\n",
        "                totals += 4 # <|im_start|>user\\n{內容}<|im_end|>\n",
        "                totals += len(encoder.encode(message[k]))\n",
        "    totals += 3 # <|im_start|>assistant\\n\n",
        "    return totals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHO6ozY5wT4J"
      },
      "outputs": [],
      "source": [
        "print(tokens_in_messages([\n",
        "        {\"role\":\"user\", \"content\": \"你好\"}\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZwKwOe8YMIv"
      },
      "source": [
        "## 深入瞭解參數"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1-ga-Tyw5Ou"
      },
      "source": [
        "### 控制生成訊息與 token 數量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODW5sx_XMSYG"
      },
      "source": [
        "#### 指定生成的訊息數量 - n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRgJDzMUilrz"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt351106\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"你好\"}],\n",
        "  n=2\n",
        ")\n",
        "\n",
        "pprint(reply)\n",
        "\n",
        "for choice in reply.choices:\n",
        "    print(choice.index,\n",
        "          choice.message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqbMN9POMUkr"
      },
      "source": [
        "#### 設定詞彙黑名單 - stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXJqNS3fjRZx"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt351106\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"你好\"}],\n",
        "  stop=['好'] # 最多 4 個\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)\n",
        "print(reply.choices[0].finish_reason)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KUb_1ELLvyc"
      },
      "source": [
        "#### 設定回覆語句的 tokens 數量上限 - max_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPrrVXy2Pf6M"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt351106\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"您好!\"}\n",
        "    ],\n",
        "    max_tokens = 5\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)\n",
        "print(reply.choices[0].finish_reason)\n",
        "print(reply.usage.completion_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lww8VuHe5TgP"
      },
      "outputs": [],
      "source": [
        "encoder.encode(\"您好！有什\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPQbUVh3L9tf"
      },
      "source": [
        "超過模型限制的 tokens 數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L-Bvt2NHDcB"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    # 用 0613 的模型示範比較節省 tokens 花費\n",
        "    model = \"gpt350613\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"你好\"}\n",
        "    ],\n",
        "    max_tokens = 4090\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp3B7u-pw_qL"
      },
      "source": [
        "### 控制回覆內容的變化性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQhZoMpINYAr"
      },
      "source": [
        "#### 讓回覆更具彈性 - temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECWZd8GUkIfj"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt350613\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"嗨！\"}],\n",
        "  temperature=0,\n",
        "  n=2\n",
        ")\n",
        "\n",
        "for choice in reply.choices:\n",
        "    print(choice.index, choice.message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXAJhTiVkRYZ"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt350613\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"嗨！\"}],\n",
        "  temperature=2,\n",
        "  n=2,\n",
        "  max_tokens=400\n",
        ")\n",
        "\n",
        "for choice in reply.choices:\n",
        "    print(choice.index, choice.message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM6fYpXYJ4P2"
      },
      "source": [
        "#### 控制詞彙的豐富度 - top_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC5i5Lt864EW"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt350613\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"嗨！\"}],\n",
        "  top_p=0,\n",
        "  n=2\n",
        ")\n",
        "\n",
        "for choice in reply.choices:\n",
        "    print(choice.index, choice.message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XwQ69fZNsDX"
      },
      "source": [
        "#### 控制詞彙的重複性 - presence_penalty 與 frequency_penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-yFTbubsROQ"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt350613\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"台北是什麼樣的城市？\"\n",
        "  }],\n",
        "  temperature=1,\n",
        "  presence_penalty=2,\n",
        "  max_tokens=400\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmsmGgpQ9oVB"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt350613\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"台北是什麼樣的城市？\"\n",
        "  }],\n",
        "  temperature=1,\n",
        "  presence_penalty=-2,\n",
        "  max_tokens=400\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_VmWcN66DDv"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt350613\",\n",
        "  messages=[{\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"台北是什麼樣的城市？\"}],\n",
        "  temperature=1, # 固定溫度會比較好測試比較\n",
        "  frequency_penalty=2,\n",
        "  max_tokens=400\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fusI2RpI90Yw"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt350613\",\n",
        "  messages=[{\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"台北是什麼樣的城市？\"}],\n",
        "  temperature=1, # 固定溫度會比較好測試比較\n",
        "  frequency_penalty=-2,\n",
        "  max_tokens=400\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc2KqtIVKBeB"
      },
      "source": [
        "#### 調整特定 token 的分數 - logi-bias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ecv9UTckKC0T"
      },
      "outputs": [],
      "source": [
        "encoder.encode('你好')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVKafC6IKGnR"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt350613\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"你好\"}],\n",
        "  temperature=1,\n",
        "  logit_bias={\n",
        "      53901: -100,\n",
        "      57668: -100\n",
        "  },\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfphuAh7KHA8"
      },
      "outputs": [],
      "source": [
        "encoder.encode('哈')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpTnB5Itj1b_"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt350613\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"你好\"}],\n",
        "  temperature=1,\n",
        "  logit_bias={\n",
        "      99771: 100\n",
        "  },\n",
        "  max_tokens=400\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tinUei5sXLh8"
      },
      "source": [
        "### 識別影像\n",
        "\n",
        "付費用戶才能使用 gpt-4-vision-preview 模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixv6erkNhcfv"
      },
      "source": [
        "#### 識別網路上的公開圖檔"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TB7TsFdXRnH"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt4vision\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"圖片裡有什麼？\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://flagtech.github.io/F3762/images/cat1.jpg\",\n",
        "                        'detail': 'high'\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqvmZOqbhXNf"
      },
      "source": [
        "#### 辨識本機的圖檔"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tngOeky_lc8"
      },
      "outputs": [],
      "source": [
        "!curl \"https://flagtech.github.io/F3762/images/cat2.jpg\" -o cat3.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQXov1_OcDZ8"
      },
      "outputs": [],
      "source": [
        "# Function to encode the image\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNs9jSuKbxPI"
      },
      "outputs": [],
      "source": [
        "base64_image = encode_image('cat3.jpg')\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt4vision\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"用中文告訴我圖片裡有什麼？\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "                        'detail': 'high'\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oBB8v9idNQb"
      },
      "source": [
        "### 串流輸出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-798ckrMcjT"
      },
      "source": [
        "#### 可循序傳回結果的生成器 (generator) - stream\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKOBD3_WdMIf"
      },
      "outputs": [],
      "source": [
        "replies = client.chat.completions.create(\n",
        "  model=\"gpt41106\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"你好\"\n",
        "  }],\n",
        "  stream=True,\n",
        ")\n",
        "\n",
        "for reply in replies:\n",
        "    pprint(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSUKBv9hk9aX"
      },
      "outputs": [],
      "source": [
        "replies = client.chat.completions.create(\n",
        "  model=\"gpt351106\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"台北是什麼樣的城市？\"\n",
        "  }],\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for reply in replies:\n",
        "    if reply.choices:\n",
        "        print(reply.choices[0].delta.content or '', end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq6AgwlP9L-q"
      },
      "source": [
        "### 控制回覆格式\n",
        "\n",
        "#### 強制 JSON 格式輸出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs7Sa7yG9ORm"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt351106\",\n",
        "    # model = \"gpt-4\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"台灣最高的山高度是多少\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL3ax4Uz9s2o"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    # response_format 一定要用 1106 模型\n",
        "    model = \"gpt351106\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"台灣最高的山高度是多少\"},\n",
        "        {\"role\":\"system\", \"content\": \"請用 json 格式回覆\"}\n",
        "    ],\n",
        "    response_format={'type': 'json_object'} # or 'text'\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDBGy-6_AdwW"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt351106\",\n",
        "    messages = [\n",
        "        {\"role\":\"system\", \"content\": \"請用 json 格式回覆\"},\n",
        "        {\n",
        "            \"role\":\"user\",\n",
        "            \"content\": \"台灣最高的山高度是多少, 請以如下格式回覆：\"\n",
        "                       '{\"name\":\"山的名稱\", \"height\":高度}'\n",
        "        },\n",
        "    ],\n",
        "    response_format={'type': 'json_object'} # or 'text'\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZFLnM0qBSKU"
      },
      "source": [
        "#### 固定輸出結果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPu-CP-5LYnY"
      },
      "outputs": [],
      "source": [
        "replies = client.chat.completions.create(\n",
        "  model=\"gpt350613\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"你好\"\n",
        "  }],\n",
        "  temperature=1.6,\n",
        "  # 同樣的種子搭配同樣的參數可以固定輸出結果\n",
        "#   seed=1\n",
        ")\n",
        "\n",
        "print(\n",
        "    replies.system_fingerprint,\n",
        "    replies.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRs8oH8qNjUB"
      },
      "outputs": [],
      "source": [
        "replies = client.chat.completions.create(\n",
        "  model=\"gpt351106\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"你好\"\n",
        "  }],\n",
        "  temperature=1.6,\n",
        "  seed=1\n",
        ")\n",
        "\n",
        "print(\n",
        "    replies.system_fingerprint,\n",
        "    replies.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BblEBT0A5C-H"
      },
      "source": [
        "## 取得底層 HTTP 的原始回覆"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXHwp-NY1EFl"
      },
      "outputs": [],
      "source": [
        "# 取得原始 HTTP 回覆內容\n",
        "reply = client.chat.completions.with_raw_response.create(\n",
        "    model = \"gpt351106\",\n",
        "    # model = \"gpt-4\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"你好\"}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lxlCxYz1K1v"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "print(reply.status_code)\n",
        "print(reply) # APIResponse 型別的物件\n",
        "print('------')\n",
        "print(reply.text) # JSON 格式文字\n",
        "print('------')\n",
        "reply_dic = json.loads(reply.text) # 轉成 Python 字典\n",
        "pprint(reply_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-fKo8FZCXLg"
      },
      "outputs": [],
      "source": [
        "print(reply_dic['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzbgDbQCMInK"
      },
      "source": [
        "## 錯誤處理與使用限制"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnqfl7R5ugIO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bycmYTRICqUA"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Exception\n",
        "  +--OpenAIError\n",
        "       +--APIError ◆ message: str\n",
        "            |      ◆ request: httpx.Request\n",
        "            +--APIResponseValidationError ◆ response: httpx.Response\n",
        "            |                             ◆ status_code: int\n",
        "            +--APIStatusError ◆ response: httpx.Response\n",
        "            |    |            ◆ status_code: int\n",
        "            |    +--BadRequestError (請求參數或是格式錯誤)\n",
        "            |    +--AuthenticationError (金鑰認證有問題)\n",
        "            |    +--PermissionDeniedError\n",
        "            |    +--NotFoundError\n",
        "            |    +--ConflictError\n",
        "            |    +--UnprocessableEntityError\n",
        "            |    +--RateLimitError (超過次數限制)\n",
        "            |    +--InternalServerError\n",
        "            +--APIConnectionError (無法連線)\n",
        "                 +--APITimeoutError (逾時)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bV1BZvzMF06"
      },
      "source": [
        "### 使用例外機制處理錯誤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHlx6477SQEo"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "try:\n",
        "    reply = client.chat.completions.create(\n",
        "        model = \"gpt350613\", # 使用 0613 模型限制小減少浪費\n",
        "        messages = [\n",
        "            {\"role\":\"user\", \"content\": \"你好\"}\n",
        "        ],\n",
        "        max_tokens = 4096\n",
        "    )\n",
        "    print(reply.choices[0].message.content)\n",
        "\n",
        "except openai.APIError as err:\n",
        "    print(err.message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8G5znxxuht"
      },
      "source": [
        "## 文字模式簡易聊天程式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X021wDnuPYlx"
      },
      "source": [
        "設計簡易對談程式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRBgH2SzEjLr"
      },
      "outputs": [],
      "source": [
        "def get_reply(messages):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model = \"gpt351106\",\n",
        "            messages = messages\n",
        "        )\n",
        "        reply = response.choices[0].message.content\n",
        "    except openai.APIError as err:\n",
        "        reply = f\"發生錯誤\\n{err.message}\"\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptsDFS0mFZ_b"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    msg = input(\"你說：\")\n",
        "    if not msg.strip(): break\n",
        "    messages = [{\"role\":\"user\", \"content\":msg}]\n",
        "    reply = get_reply(messages)\n",
        "    print(f\"ㄟ唉：{reply}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyO0gDj7yD5M"
      },
      "source": [
        "### 加入聊天記錄維持聊天脈絡"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIsWBAoaPj1z"
      },
      "source": [
        "把歷史紀錄加入 prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V--0U28tI17U"
      },
      "outputs": [],
      "source": [
        "hist = []       # 歷史對話紀錄\n",
        "backtrace = 2   # 記錄幾組對話\n",
        "\n",
        "def chat(sys_msg, user_msg):\n",
        "    global hist\n",
        "    hist.append({\"role\":\"user\", \"content\":user_msg})\n",
        "    reply = get_reply(hist\n",
        "                      + [{\"role\":\"system\", \"content\":sys_msg}])\n",
        "    hist.append({\"role\":\"assistant\", \"content\":reply})\n",
        "    hist = hist[-2 * backtrace:] # 保留新的對話\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwhnfM-6JAvA"
      },
      "outputs": [],
      "source": [
        "sys_msg = input(\"你希望ㄟ唉扮演：\")\n",
        "if not sys_msg.strip(): sys_msg = '繁體中文小助理'\n",
        "print()\n",
        "while True:\n",
        "    msg = input(\"你說：\")\n",
        "    if not msg.strip(): break\n",
        "    reply = chat(sys_msg, msg)\n",
        "    print(f\"{sys_msg}:{reply}\\n\")\n",
        "hist = [] # 清除對話記錄以免影響後續測試"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqa3sGEDyMp1"
      },
      "source": [
        "### 串流版本的聊天程式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Ge034UfYDd"
      },
      "source": [
        "串流版本的聊天程式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpHqQNiMfemv"
      },
      "outputs": [],
      "source": [
        "def get_reply_s(messages):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model = \"gpt351106\",\n",
        "            messages = messages,\n",
        "            stream = True\n",
        "        )\n",
        "        for chunk in response:\n",
        "            if chunk.choices: # 略過第一個只有適合度資料的片段\n",
        "                yield chunk.choices[0].delta.content or ''\n",
        "    except openai.APIError as err:\n",
        "        reply = f\"發生錯誤\\n{err.message}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZciBFLufywW"
      },
      "outputs": [],
      "source": [
        "for reply in get_reply_s([{\n",
        "    \"role\":\"user\",\n",
        "    \"content\":\"請介紹台北市\"\n",
        "}]):\n",
        "    print(reply, end='')\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UIcjOjqgffE"
      },
      "outputs": [],
      "source": [
        "hist = []       # 歷史對話紀錄\n",
        "backtrace = 2   # 記錄幾組對話\n",
        "\n",
        "def chat_s(sys_msg, user_msg):\n",
        "    global hist\n",
        "    hist.append({\"role\":\"user\", \"content\":user_msg})\n",
        "    reply_full = \"\"\n",
        "    for reply in get_reply_s(         # 使用串流版的函式\n",
        "        hist + [{\"role\":\"system\", \"content\":sys_msg}]):\n",
        "        reply_full += reply           # 記錄到目前為止收到的訊息\n",
        "        yield reply                   # 傳回本次收到的片段訊息\n",
        "    hist.append({\"role\":\"assistant\", \"content\":reply_full})\n",
        "    hist = hist[-2 * backtrace:]      # 保留最新的對話"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21fxgL_qg7r-"
      },
      "outputs": [],
      "source": [
        "sys_msg = input(\"你希望ㄟ唉扮演：\")\n",
        "if not sys_msg.strip(): sys_msg = '小助理'\n",
        "print()\n",
        "while True:\n",
        "    msg = input(\"你說：\")\n",
        "    if not msg.strip(): break\n",
        "    print(f\"{sys_msg}：\", end = \"\")\n",
        "    for reply in chat_s(sys_msg, msg):\n",
        "        print(reply, end = \"\")\n",
        "    print('\\n')\n",
        "    # pprint(hist)\n",
        "hist = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNYngg3YPEp5"
      },
      "source": [
        "## 突破時空限制–整合搜尋功能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O-zz4SSzPoF"
      },
      "source": [
        "### 用搜尋網頁幫 AI 補充知識"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f814Yd_fRBA0"
      },
      "source": [
        "### 使用 Google 搜尋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtHx23DvU-T5"
      },
      "outputs": [],
      "source": [
        "!pip install googlesearch-python\n",
        "from googlesearch import search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2IzKRzZWVjc"
      },
      "outputs": [],
      "source": [
        "for item in search(\"2023 金曲獎歌后\"):\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtPAfyxARHBn"
      },
      "source": [
        "使用進階搜尋選項"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMx3LddFXEHc"
      },
      "outputs": [],
      "source": [
        "for item in search(\n",
        "    \"2023 金曲獎歌后\", advanced=True, num_results=3):\n",
        "    print(item.title)\n",
        "    print(item.description)\n",
        "    print(item.url)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjc6Vdv9zmSF"
      },
      "source": [
        "### 整合搜尋結果讓 AI 跟上時代"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IafW58_7IkpG"
      },
      "source": [
        "加入網頁搜尋的聊天程式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhiWJ8txIkpG"
      },
      "outputs": [],
      "source": [
        "hist = []       # 歷史對話紀錄\n",
        "backtrace = 2   # 記錄幾組對話\n",
        "\n",
        "def chat_w(sys_msg, user_msg):\n",
        "    global hist\n",
        "    web_res = []\n",
        "    if user_msg[:3].lower() == '/w ': # /w 代表要搜尋網路\n",
        "        user_msg = user_msg[3:]       # 移除指令留下實際的訊息\n",
        "        content = \"以下為已發生的事實：\\n\"\n",
        "        for res in search(user_msg, advanced=True,\n",
        "                          num_results=5, lang='zh-TW'):\n",
        "            content += f\"標題：{res.title}\\n\" \\\n",
        "                       f\"摘要：{res.description}\\n\\n\"\n",
        "        content += \"請依照上述事實回答以下問題：\\n\"\n",
        "        web_res = [{\"role\": \"user\", \"content\": content}]\n",
        "    web_res.append({\"role\": \"user\", \"content\": user_msg})\n",
        "    reply_full = \"\"\n",
        "    for reply in get_reply_s(         # 使用串流版的函式\n",
        "        hist                          # 先提供歷史紀錄\n",
        "        + web_res                     # 再提供搜尋結果及目前訊息\n",
        "        + [{\"role\": \"system\", \"content\": sys_msg}]):\n",
        "        reply_full += reply           # 記錄到目前為止收到的訊息\n",
        "        yield reply                   # 傳回本次收到的片段訊息\n",
        "    hist.append({\"role\": \"user\", \"content\": user_msg})\n",
        "    hist.append({\"role\":\"assistant\", \"content\":reply_full})\n",
        "    hist = hist[-2 * backtrace:]      # 保留最新對話"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIXa5pX2IkpG"
      },
      "outputs": [],
      "source": [
        "sys_msg = input(\"你希望ㄟ唉扮演：\")\n",
        "if not sys_msg.strip(): sys_msg = '使用繁體中文的小助理'\n",
        "print()\n",
        "while True:\n",
        "    msg = input(\"你說：\")\n",
        "    if not msg.strip(): break\n",
        "    print(f\"{sys_msg}：\", end = \"\")\n",
        "    for reply in chat_w(sys_msg, msg):\n",
        "        print(reply, end = \"\")\n",
        "    print('\\n')\n",
        "hist = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcsCqK-ERtTb"
      },
      "source": [
        "### 使用客製模組"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtOV_E5P3Wbe"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/codemee/customsearchapi.git customsearchapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_liR9utq3dvS"
      },
      "outputs": [],
      "source": [
        "# 預設會在匯入時從環境變數 GOOGLE_API_KEY 與 GOOGLE_ID\n",
        "# 讀取你的 API Key 與搜尋引擎 ID,\n",
        "# 如果沒有設定, 也可以直接透過模組內的變數設定：\n",
        "import customsearchapi\n",
        "customsearchapi.GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "customsearchapi.GOOGLE_CSE_ID = userdata.get('GOOGLE_CSE_ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ha1xFSm4VhA"
      },
      "outputs": [],
      "source": [
        "from customsearchapi import search\n",
        "\n",
        "for item in search(\"2023 NBA 冠軍\",\n",
        "                   advanced=True,\n",
        "                   num_results=3,\n",
        "                   lang='zh-TW'):\n",
        "    print(item.url)\n",
        "    print(item.title)\n",
        "    print(item.description)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVLUFQMKa3rc"
      },
      "source": [
        "## 讓 AI 幫 AI－自動串接流程"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQoeKOv30XwE"
      },
      "source": [
        "### 從 ChatGPT 外掛得到的啟示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONHyAgPZa3rd"
      },
      "outputs": [],
      "source": [
        "def get_reply_g(messages, stream=False, json_format=False):\n",
        "    try:\n",
        "        json_msg = ([{'role': 'system', 'content': '請用 JSON 回覆'}]\n",
        "                    if json_format else [])\n",
        "        response = client.chat.completions.create(\n",
        "            model = \"gpt351106\",\n",
        "            messages = messages + json_msg,\n",
        "            stream = stream,\n",
        "            response_format = {\n",
        "                'type': \"json_object\" if json_format else 'text'\n",
        "            }\n",
        "        )\n",
        "        if stream: # 串留模式下以生成器傳回片段內容\n",
        "            for res in response:\n",
        "                if res.choices:\n",
        "                    yield res.choices[0].delta.content or ''\n",
        "        else:      # 非串流模式下可直接取得完整回覆文字\n",
        "            yield response.choices[0].message.content\n",
        "    except openai.APIError as err:\n",
        "        reply = f\"發生錯誤\\n{err.message}\"\n",
        "        print(reply)\n",
        "        yield reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iugjm69PSbfF"
      },
      "outputs": [],
      "source": [
        "# 測試非串流模式\n",
        "for reply in get_reply_g([{'role':'user', 'content':'你好'}]):\n",
        "    print(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec1Nb2keZlg_"
      },
      "outputs": [],
      "source": [
        "# 測試串流模式\n",
        "for msg in get_reply_g([{'role':'user', 'content':'你好'}], stream=True):\n",
        "    print(msg, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiyZiwM7RBdp"
      },
      "outputs": [],
      "source": [
        "# 測試 JSON 格式輸出\n",
        "for reply in get_reply_g(\n",
        "    [{'role':'user', 'content':'你好'}],\n",
        "    json_format=True\n",
        "):\n",
        "    print(reply)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ontn4Qp0nDb"
      },
      "source": [
        "### 由 AI 自動判斷要額外進行的工作"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4__qmyBb1sd"
      },
      "source": [
        "#### 撰寫判斷是否需要搜尋的工具函式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-utgajNExsEE"
      },
      "outputs": [],
      "source": [
        "# 用來詢問是否需要搜尋才能回覆問題的樣板\n",
        "# 要求 AI 以 JSON 格式回覆 Y/N 以及建議的搜尋關鍵字\n",
        "template_google = '''\n",
        "如果我想知道以下這件事, 請確認是否需要網路搜尋才做得到？\n",
        "\n",
        "```\n",
        "{}\n",
        "```\n",
        "\n",
        "如果需要, 請以下列 JSON 格式回答我, 除了 JSON 格式資料外,\n",
        "不要加上額外資訊, 就算你知道答案, 也不要回覆：\n",
        "\n",
        "```\n",
        "{{\n",
        "    \"search\":\"Y\",\n",
        "    \"keyword\":\"你建議的搜尋關鍵字\"\n",
        "}}\n",
        "```\n",
        "如果不需要, 請以下列 JSON 格式回答我：\n",
        "\n",
        "```\n",
        "{{\n",
        "    \"search\":\"N\",\n",
        "    \"keyword\":\"\"\n",
        "}}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wBoRh5aMaUR"
      },
      "outputs": [],
      "source": [
        "# 利用目前歷史紀錄以及樣板內容詢問是否需要搜尋才能回覆問題\n",
        "# 如果需要回覆, 也同時取得 AI 推薦的搜尋關鍵字\n",
        "def check_google(hist, msg, verbose=False):\n",
        "    reply = get_reply_g(\n",
        "        hist + [{  # 加入歷史紀錄 AI 才能推薦正確的關鍵字\n",
        "            \"role\": \"user\",\n",
        "            \"content\": template_google.format(msg)\n",
        "        }], json_format=True)\n",
        "    for ans in reply:pass\n",
        "    if verbose: print(ans)\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0HzE8hQM5sT"
      },
      "outputs": [],
      "source": [
        "# 測試需要搜尋的狀況\n",
        "ans = check_google(\n",
        "    [], '2023 NBA 冠軍是哪一隊？', True\n",
        ")\n",
        "# 測試可能不需要搜尋的狀況\n",
        "ans = check_google(\n",
        "    [], '新冠疫情是哪一年開始的？', True\n",
        ")\n",
        "# 測試沒有前文脈絡的狀況\n",
        "ans = check_google(\n",
        "    [], '那台灣呢？', True\n",
        ")\n",
        "# 測試包含前文脈絡的狀況\n",
        "ans = check_google(\n",
        "    [{'role':'assistant', 'content': '印度空污好嚴重'}],\n",
        "    '那台灣呢？', True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3ng7lsCbH6D"
      },
      "outputs": [],
      "source": [
        "def google_res(user_msg, num_results=5, verbose=False):\n",
        "    content = \"以下為已發生的事實：\\n\"                # 強調資料可信度\n",
        "    for res in search(user_msg, advanced=True,    # 一一串接搜尋結果\n",
        "                      num_results=num_results,\n",
        "                      lang='zh-TW'):\n",
        "        content += f\"標題：{res.title}\\n\" \\\n",
        "                    f\"摘要：{res.description}\\n\\n\"\n",
        "    # content += \"請依照上述事實回答以下問題：\\n\"        # 下達明確指令\n",
        "    if verbose:\n",
        "        print('------------')\n",
        "        print(content)\n",
        "        print('------------')\n",
        "    return content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RtZC9BLuJpv"
      },
      "outputs": [],
      "source": [
        "res = google_res('2023 NBA 冠軍隊', 2, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UilIxFrRSxYK"
      },
      "source": [
        "### 可自行判斷是否進行網路搜尋的聊天程式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLRYkJ1IerqD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "hist = []       # 歷史對話紀錄\n",
        "backtrace = 2   # 記錄幾組對話\n",
        "\n",
        "def chat_g(sys_msg, user_msg, stream=False, verbose=False):\n",
        "    global hist\n",
        "    messages = [{'role':'user', 'content':user_msg}]\n",
        "    ans = json.loads(check_google(hist, user_msg,\n",
        "                                  verbose=verbose))\n",
        "    if ans['search'] == 'Y':\n",
        "        print(f'嘗試透過網路搜尋：{ans[\"keyword\"]}....')\n",
        "        res = google_res(ans['keyword'], verbose=verbose)\n",
        "        messages = [{'role':'user', 'content': res + user_msg}]\n",
        "\n",
        "    replies = get_reply_g(            # 使用搜尋版的函式\n",
        "        hist        # 先提供歷史紀錄\n",
        "        + messages  # 再提供搜尋結果及目前訊息\n",
        "        + [{\"role\": \"system\", \"content\": sys_msg}],\n",
        "        stream)\n",
        "    reply_full = ''\n",
        "    for reply in replies:\n",
        "        reply_full += reply\n",
        "        yield reply\n",
        "\n",
        "    hist.append({\"role\":\"user\", \"content\":user_msg})\n",
        "    hist.append({\"role\":\"assistant\", \"content\":reply_full})\n",
        "    hist = hist[-2 * backtrace:] # 保留最新對話"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JWrI77ierqD"
      },
      "outputs": [],
      "source": [
        "sys_msg = input(\"你希望ㄟ唉扮演：\")\n",
        "if not sys_msg.strip(): sys_msg = '使用繁體中文的小助理'\n",
        "print()\n",
        "\n",
        "while True:\n",
        "    msg = input(\"你說：\")\n",
        "    if not msg.strip(): break\n",
        "    print(f\"{sys_msg}：\", end = \"\")\n",
        "    # 不論是字串或是生成器, 都可以適用 for...in 迴圈\n",
        "    for reply in chat_g(sys_msg, msg, stream=False):\n",
        "        print(reply, end = \"\")\n",
        "    print('\\n')\n",
        "hist = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR66bWoL1MEG"
      },
      "source": [
        "## 可建構外掛系統的 Function Calling 機制"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byrjSV6Wv5i2"
      },
      "source": [
        "**Function calling 機制**\n",
        "\n",
        "Function calling 機制可以讓我們提供可用函式的規格, 由 AI 幫我們判斷是否需要叫用其中的函式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33kQwvMXqnPO"
      },
      "source": [
        "### 告知語言模型可用的外部工具函式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV2VyR2GoPpe"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt41106\",\n",
        "    messages = [{\"role\":\"user\", \"content\":\"2023 金曲歌后？\"}],\n",
        "    tools = [{ # 可用的函式清單\n",
        "        \"type\":\"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"google_res\",                     # 函式名稱\n",
        "            \"description\": \"取得 Google 搜尋結果\",      # 函式說明\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"user_msg\": {                     # 參數名稱\n",
        "                        \"type\": \"string\",             # 資料類型\n",
        "                        \"description\": \"要搜尋的關鍵字\", # 參數說明\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"user_msg\"],             # 必要參數\n",
        "            },\n",
        "        }\n",
        "    }],\n",
        "    tool_choice = \"auto\")       # 請 AI 判斷是否需要叫用函式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNOcLUYwq0Vu"
      },
      "source": [
        "若 API 判斷需要叫用你描述的函式, 會在回覆中以 function_call 項目描述要叫用的函式名稱與參數值。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf9b8aoETuof"
      },
      "source": [
        "### 取得語言模型的建議"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yI_HsqeBuYq"
      },
      "outputs": [],
      "source": [
        "pprint(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUSrFvHE0IM4"
      },
      "outputs": [],
      "source": [
        "tool_call = response.choices[0].message.tool_calls[0]\n",
        "func_name = tool_call.function.name\n",
        "import json\n",
        "args = json.loads(tool_call.function.arguments)\n",
        "arg_val = args.popitem()[1]\n",
        "print(f'{func_name}(\"{arg_val}\")')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwnrQzio3wQK"
      },
      "source": [
        "### 執行函式並傳回結果\n",
        "\n",
        "你必須自行叫用函式, 並且將執行結果透過 tool 角色的訊息傳回。\n",
        "\n",
        "要注意的是, 傳回時要一併送回原本模型送過來, 包含有 tool_calls 內容的訊息, 不過這個訊息因為考慮到相容性的關係, 所以除了 tool_calls 外, 還放了值為 None 的 function_call 欄位, 但這個欄位在請求中是 tool_choice 的功能, 如果連同這個欄位傳回, API 端會出錯, 認為這是不正確的參數, 因此目前的作法是透過自訂函式 maker_tool_back_msg 來客製一個訊息, 濾掉不需要傳回去的 function_call 欄位。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynPG9RTJxaCU"
      },
      "outputs": [],
      "source": [
        "# 用來過濾掉訊息中 function_call 欄位的函式\n",
        "def make_tool_back_msg(tool_msg):\n",
        "    msg_json = tool_msg.model_dump()\n",
        "    del msg_json['function_call']\n",
        "    return msg_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nybm9QfezrdT"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model='gpt41106',\n",
        "    messages=[\n",
        "        {\"role\":\"user\", \"content\":\"2023 金曲歌后？\"},\n",
        "        # 傳回 AI 傳給我們的 function calling 結果\n",
        "        make_tool_back_msg(response.choices[0].message),\n",
        "        {   # 以 function 角色加上 name 屬性指定函式名稱傳回執行結果\n",
        "            \"tool_call_id\": tool_call.id, # 叫用函式的識別碼\n",
        "            \"role\": \"tool\", # 以工具角色送出回覆\n",
        "            \"name\": func_name, # 叫用的函式名稱\n",
        "            \"content\": eval(f'{func_name}(\"{arg_val}\")') # 函式傳回值\n",
        "        }\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNzBfp03052c"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qActYIH0YeVY"
      },
      "source": [
        "\n",
        "2023/11/06 之後的模型支援單次對話可以要求執行多個函式呼叫："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxwScFYoVHnQ"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt41106\",\n",
        "    messages = [{\"role\":\"user\", \"content\":\"2023 金馬獎影后和金曲獎歌王各是誰？\"}],\n",
        "    tools = [{ # 可用的函式清單\n",
        "        \"type\":\"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"google_res\",                     # 函式名稱\n",
        "            \"description\": \"取得 Google 搜尋結果\",      # 函式說明\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"user_msg\": {                     # 參數名稱\n",
        "                        \"type\": \"string\",             # 資料類型\n",
        "                        \"description\": \"要搜尋的關鍵字\", # 參數說明\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"user_msg\"],             # 必要參數\n",
        "            },\n",
        "        }\n",
        "    }],\n",
        "    tool_choice = \"auto\")       # 請 AI 判斷是否需要叫用函式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivEmFRleXTPr"
      },
      "outputs": [],
      "source": [
        "pprint(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuCnmiOAVRfu"
      },
      "outputs": [],
      "source": [
        "for tool_call in response.choices[0].message.tool_calls:\n",
        "    func = tool_call.function\n",
        "    func_name = func.name\n",
        "    args_val = json.loads(func.arguments).popitem()[1]\n",
        "    print(f'{func.name}(\"{args_val}\")')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHqRidVVbMsB"
      },
      "outputs": [],
      "source": [
        "def make_func_messages(tool_calls):\n",
        "    messages = []\n",
        "    for tool_call in tool_calls:\n",
        "        func = tool_call.function\n",
        "        func_name = func.name\n",
        "        args_val = json.loads(func.arguments).popitem()[1]\n",
        "        print(f'{func.name}(\"{args_val}\")')\n",
        "        messages.append({\n",
        "            \"tool_call_id\": tool_call.id, # 叫用函式的識別碼\n",
        "            \"role\": \"tool\", # 以工具角色送出回覆\n",
        "            \"name\": func.name, # 叫用的函式名稱\n",
        "            \"content\": eval(f'{func_name}(\"{args_val}\")') # 函式傳回值\n",
        "        })\n",
        "    return messages\n",
        "\n",
        "func_messages = make_func_messages(response.choices[0].message.tool_calls)\n",
        "pprint(func_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyzsNlibZ4bn"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model='gpt41106',\n",
        "    messages=[\n",
        "        {\"role\":\"user\", \"content\":\"2023 金馬獎影后和金曲獎歌王各是誰？\"},\n",
        "        # 傳回 AI 傳給我們的 function calling 結果\n",
        "        make_tool_back_msg(response.choices[0].message),\n",
        "    ] + func_messages\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwJCg4ujg1NA"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M527Isb35K_m"
      },
      "source": [
        "### 以串流方式使用 function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8zKX0Nf3Es9"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    # model = \"gpt41106\",\n",
        "    model = \"gpt351106\",\n",
        "    messages = [{\"role\":\"user\", \"content\":\"宮崎駿和是枝裕和的最新作品各是哪一部？\"}],\n",
        "    tools = [{\n",
        "        \"type\": \"function\",                           # 工具類型\n",
        "        \"function\": {\n",
        "            \"name\": \"google_res\",                     # 函式名稱\n",
        "            \"description\": \"取得 Google 搜尋結果\",      # 函式說明\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"user_msg\": {                     # 參數名稱\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"要搜尋的關鍵字\", # 參數說明\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"user_msg\"],\n",
        "            },\n",
        "        }\n",
        "    }],\n",
        "    tool_choice = \"auto\", # 請 AI 判斷是否需要使用工具\n",
        "    stream=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G8g3ln85lgI"
      },
      "source": [
        "傳回結果一樣是可走訪物件。\n",
        "\n",
        "注意, 1106 的模型第一個 chunk 沒有函式名稱, 第二個 chunk 之後才有 function calling 的資料。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43D-blzoW9Rx"
      },
      "outputs": [],
      "source": [
        "for chunk in response:\n",
        "    pprint(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLEYI9KL1amp"
      },
      "source": [
        "## 建立 API 外掛系統"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RRoqgB-UKOF"
      },
      "source": [
        "### 建立外部工具函式參考表"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50TGN5_lr226"
      },
      "source": [
        "建立以 function calling 為基礎的外掛機制。<br>\n",
        "建立結構化的函式表格。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJtnKbIN6XYP"
      },
      "outputs": [],
      "source": [
        "tools_table = [             # 可用工具表\n",
        "    {                       # 每個元素代表一個工具\n",
        "        \"chain\": True,      # 工具執行結果是否要再傳回給 API\n",
        "        \"func\": google_res, # 工具對應的函式\n",
        "        \"spec\": {           # function calling 需要的工具規格\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"google_res\",\n",
        "                \"description\": \"取得 Google 搜尋結果\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"user_msg\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"要搜尋的關鍵字\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"user_msg\"],\n",
        "                },\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0GQMNX7sKCI"
      },
      "source": [
        "### 建立協助 function calling 的工具函式\n",
        "依據回應內容自動叫用對應函式："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSaSvwtMWovK"
      },
      "outputs": [],
      "source": [
        "def call_tools(tool_calls, tools_table):\n",
        "    res = ''\n",
        "    msg = []\n",
        "    for tool_call in tool_calls:\n",
        "        func = tool_call.function\n",
        "        func_name = func.name\n",
        "        args = json.loads(func.arguments)\n",
        "        for f in tools_table:  # 找出包含此函式的項目\n",
        "            if func_name == f['spec']['function']['name']:\n",
        "                print(f\"嘗試叫用：{func_name}(**{args})\")\n",
        "                val = f['func'](**args)\n",
        "                if f['chain']: # 要將結果送回模型\n",
        "                    msg.append({\n",
        "                        'tool_call_id': tool_call.id,\n",
        "                        'role': 'tool',\n",
        "                        'name': 'func_name',\n",
        "                        'content': val\n",
        "                    })\n",
        "                else: res += str(val)\n",
        "                break\n",
        "    return msg, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVa9UmFAbnI0"
      },
      "outputs": [],
      "source": [
        "def get_tool_calls(messages, stream=False, tools_table=None,\n",
        "                  **kwargs):\n",
        "    model = 'gpt351106' # 設定模型\n",
        "    if 'model' in kwargs: model = kwargs['model']\n",
        "\n",
        "    tools = {}\n",
        "    if tools_table: # 加入工具表\n",
        "        tools = {'tools':[tool['spec'] for tool in tools_table]}\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model = model,\n",
        "        messages = messages,\n",
        "        stream = stream,\n",
        "        **tools\n",
        "    )\n",
        "\n",
        "    if not stream: # 非串流模式\n",
        "        msg = response.choices[0].message\n",
        "        if msg.content == None: # function calling 的回覆\n",
        "            return msg.tool_calls, None # 取出叫用資訊\n",
        "        return None, response # 一般回覆\n",
        "\n",
        "    tool_calls = [] # 要呼叫的函式清單\n",
        "    prev = None\n",
        "    for chunk in response:\n",
        "        if not chunk.choices: continue # 略過 Azure 串流的第一個片段\n",
        "        delta = chunk.choices[0].delta\n",
        "        if delta.content != None: # 一般回覆 (非 function calling)\n",
        "            return None, response # 直接返回結果\n",
        "        if delta.tool_calls:      # 不是頭/尾的 chunk\n",
        "            curr = delta.tool_calls[0]\n",
        "            if curr.function.name:       # 單一 call 開始\n",
        "                prev = curr              # 取得工具名稱\n",
        "                tool_calls.append(curr)  # 加入串列\n",
        "            else: # 串接引數內容\n",
        "                prev.function.arguments += curr.function.arguments\n",
        "    return tool_calls, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VPoLmupNhtN"
      },
      "outputs": [],
      "source": [
        "pprint(get_tool_calls(\n",
        "    messages = [{'role':'user', 'content':'2023 金曲歌王是哪位？'}]\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvGmInUSOW-O"
      },
      "outputs": [],
      "source": [
        "tool_calls, response = get_tool_calls(\n",
        "    messages = [{'role':'user', 'content':'2023 金曲歌王是哪位？'}],\n",
        "    stream=True\n",
        ")\n",
        "for chunk in response:\n",
        "    print(chunk.choices[0].delta.content or '', end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btpkyh4WPepL"
      },
      "outputs": [],
      "source": [
        "tool_calls, response = get_tool_calls(\n",
        "    messages = [{'role':'user', 'content':'2023 金曲歌王是哪位？'}],\n",
        "    tools_table=tools_table\n",
        ")\n",
        "pprint(tool_calls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8yvRhj3P_hw"
      },
      "outputs": [],
      "source": [
        "tool_calls, response = get_tool_calls(\n",
        "    messages = [{'role':'user', 'content':'2023 金曲歌王是哪位？'}],\n",
        "    stream=True,\n",
        "    tools_table=tools_table\n",
        ")\n",
        "pprint(tool_calls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpOlNDlcYQiK"
      },
      "outputs": [],
      "source": [
        "tool_calls, response = get_tool_calls(\n",
        "    messages = [{'role':'user', 'content':'宮崎駿和是枝裕和的最新作品各是哪一部？'}],\n",
        "    stream=True,\n",
        "    tools_table=tools_table,\n",
        "    # model='gpt41106'\n",
        ")\n",
        "pprint(tool_calls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqLCfWNPUvi_"
      },
      "source": [
        "### 建立 function_calling 版的 get_reply_f() 函式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_HyReryakU5"
      },
      "outputs": [],
      "source": [
        "def get_reply_f(messages, stream=False, tools_table=None, **kwargs):\n",
        "    try:\n",
        "        tool_calls, response = get_tool_calls(messages,\n",
        "                                            stream, tools_table, **kwargs)\n",
        "        if tool_calls:\n",
        "            tool_messages, res = call_tools(tool_calls, tools_table)\n",
        "            tool_calls_messeges = []\n",
        "            for tool_call in tool_calls:\n",
        "                tool_calls_messeges.append(tool_call.model_dump())\n",
        "            if tool_messages:  # 如果需要將函式執行結果送回給 AI 再回覆\n",
        "                messages += [ # 必須傳回原本 function_calling 的內容\n",
        "                    {\n",
        "                        \"role\": \"assistant\", \"content\": None,\n",
        "                        \"tool_calls\": tool_calls_messeges\n",
        "                    }]\n",
        "                messages += tool_messages\n",
        "                # pprint(messages)\n",
        "                yield from get_reply_f(messages, stream,\n",
        "                                       tools_table, **kwargs)\n",
        "            else:      # chain 為 False, 以函式叫用結果當成模型生成內容\n",
        "                yield res\n",
        "        elif stream:   # 不需叫用函式但使用串流模式\n",
        "            for chunk in response:\n",
        "                if chunk.choices: # 略過 Azure 串流的第一個片段\n",
        "                    yield chunk.choices[0].delta.content or ''\n",
        "        else:          # 不需叫用函式也沒有使用串流模式\n",
        "            yield response.choices[0].message.content\n",
        "    except openai.APIError as err:\n",
        "        reply = f\"發生錯誤\\n{err.message}\"\n",
        "        print(reply)\n",
        "        yield reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLO76nV4Ealo"
      },
      "outputs": [],
      "source": [
        "# 測試非串流方式 function_calling 功能\n",
        "for chunk in get_reply_f(\n",
        "    [{\"role\":\"user\", \"content\":\"2023 金曲歌后是誰？\"}],\n",
        "    tools_table=tools_table):\n",
        "    print(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNioKT6Vodaf"
      },
      "outputs": [],
      "source": [
        "# 測試串流方式 function_calling 功能\n",
        "for chunk in get_reply_f(\n",
        "    [{\"role\":\"user\", \"content\":\"2023 金曲歌后是誰？\"}],\n",
        "    stream=True,\n",
        "    tools_table=tools_table):\n",
        "    print(chunk, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m23Ds5BOtVnS"
      },
      "outputs": [],
      "source": [
        "# 測試非串流、無 function calling 功能\n",
        "for chunk in get_reply_f(\n",
        "    [{\"role\":\"user\", \"content\":\"2023 金曲歌后是誰？\"}]):\n",
        "    print(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay2vtRj3td6q"
      },
      "outputs": [],
      "source": [
        "# 測試串流、無 function calling 功能\n",
        "for chunk in get_reply_f(\n",
        "    [{\"role\":\"user\", \"content\":\"2023 金曲歌后是誰？\"}],\n",
        "    stream=True):\n",
        "    print(chunk, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNNLNn6pnkK7"
      },
      "outputs": [],
      "source": [
        "# 測試串流方式 function_calling 功能\n",
        "for chunk in get_reply_f(\n",
        "    [{\"role\":\"user\", \"content\":\"宮崎駿和是枝裕和的最新作品各是哪一部？\"}],\n",
        "    stream=True,\n",
        "    tools_table=tools_table,\n",
        "    # model='gpt41106'\n",
        "):\n",
        "    print(chunk, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajlSC5PPVBnq"
      },
      "source": [
        "### 建立 function calling 版本的 chat_f() 函式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSpzuVo7yo-M"
      },
      "outputs": [],
      "source": [
        "hist = []       # 歷史對話紀錄\n",
        "backtrace = 2   # 記錄幾組對話\n",
        "\n",
        "def chat_f(sys_msg, user_msg, stream=False, **kwargs):\n",
        "    global hist\n",
        "\n",
        "    replies = get_reply_f(    # 使用函式功能版的函式\n",
        "        hist                  # 先提供歷史紀錄\n",
        "        + [{\"role\": \"user\", \"content\": user_msg}]\n",
        "        + [{\"role\": \"system\", \"content\": sys_msg}],\n",
        "        stream, tools_table, **kwargs)\n",
        "    reply_full = ''\n",
        "    for reply in replies:\n",
        "        reply_full += reply\n",
        "        yield reply\n",
        "\n",
        "    hist += [{\"role\":\"user\", \"content\":user_msg},\n",
        "             {\"role\":\"assistant\", \"content\":reply_full}]\n",
        "    hist = hist[-2 * backtrace:] # 留下最新的對話"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rR4R1uOuLhx"
      },
      "outputs": [],
      "source": [
        "sys_msg = input(\"你希望ㄟ唉扮演：\")\n",
        "if not sys_msg.strip(): sys_msg = '使用繁體中文的小助理'\n",
        "print()\n",
        "while True:\n",
        "    msg = input(\"你說：\")\n",
        "    if not msg.strip(): break\n",
        "    print(f\"{sys_msg}：\", end = \"\")\n",
        "    for reply in chat_f(sys_msg, msg, stream=True):\n",
        "        print(reply, end = \"\")\n",
        "    print('\\n')\n",
        "hist = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA5OOLjP4Q0T"
      },
      "source": [
        "## 使用 DALL‧E 的 Image API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5NzRvvK80h2"
      },
      "source": [
        "### Image API 用法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juK-91EWDgvw"
      },
      "source": [
        "Dall-e-3 模型\n",
        "\n",
        "1024x1024, 1792x1024, or 1024x1792\n",
        "\n",
        "注意：Azure 中 api_version 要用 2023-12-01-preview 才行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsJq8Hlw-fWT"
      },
      "outputs": [],
      "source": [
        "res = client.images.generate(   # 文字生圖\n",
        "    model='Dalle3',\n",
        "    prompt='夕陽下駛過海邊的火車', # 描述文字\n",
        "    n=1,                        # 生圖張數\n",
        "    quality='hd',\n",
        "    size='1024x1024',           # 影像大小, 預設 1024x1024\n",
        "    style='vivid',            # 風格, 預設 'vivid'\n",
        ")\n",
        "pprint(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v43-3oQd3zc"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVROEax9fBGS"
      },
      "outputs": [],
      "source": [
        "display(Image(url=res.data[0].url, width=200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcuHC9YmEpKY"
      },
      "outputs": [],
      "source": [
        "print(res.data[0].revised_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwPVb7hceBHw"
      },
      "outputs": [],
      "source": [
        "display(Markdown(f\"![]({res.data[0].url})\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9ZE2kKWXrxx"
      },
      "source": [
        "### 建立文字生圖像網址的函式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge1xqcrCBeWd"
      },
      "outputs": [],
      "source": [
        "def txt_to_img_url(prompt):\n",
        "    response = client.images.generate(\n",
        "        model='Dalle3',\n",
        "        prompt=prompt,\n",
        "        n=1,\n",
        "        size='1024x1024',\n",
        "        style='vivid',\n",
        "        quality='hd'\n",
        "    )\n",
        "    return response.data[0].url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OogZKOJ9B3f_"
      },
      "outputs": [],
      "source": [
        "display(Image(url=txt_to_img_url('田邊騎著腳踏車晃的少年'), width=200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh0CFGhiC07Y"
      },
      "outputs": [],
      "source": [
        "tools_table.append({                    # 每個元素代表一個函式\n",
        "    \"chain\": False,  # 生圖後不需要傳回給 API\n",
        "    \"func\": txt_to_img_url,\n",
        "    \"spec\": {        # function calling 需要的函式規格\n",
        "        'type': 'function',\n",
        "        'function': {\n",
        "            \"name\": \"txt_to_img_url\",\n",
        "            \"description\": \"可由文字生圖並傳回圖像網址\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"prompt\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"描述要產生圖像內容的文字\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"prompt\"],\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q42dWiLwDvNp"
      },
      "outputs": [],
      "source": [
        "for chunk in chat_f('小助理', '請畫一張夕陽下海豚躍出海面的圖像', False):\n",
        "    if chunk.startswith('https'):\n",
        "        display(Image(url=chunk, width=300))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0o41v7E4Ka1"
      },
      "source": [
        "## 使用 gradio 套件快速建立網頁程式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdxBFtLh83QD"
      },
      "source": [
        "### 安裝與使用 gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBotGWq1rH6G"
      },
      "outputs": [],
      "source": [
        "#!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmBZZNCU88us"
      },
      "source": [
        "建立基本的網頁介面"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0QYgtoxQEPH"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRkqv4VGrgYh"
      },
      "outputs": [],
      "source": [
        "hist = []\n",
        "web_chat = gr.Interface(\n",
        "    fn = chat_f,\n",
        "    inputs = ['text', 'text'],\n",
        "    outputs = ['text'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-kRoO1JsGq2"
      },
      "outputs": [],
      "source": [
        "web_chat.queue()\n",
        "web_chat.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u30T026Tshcg"
      },
      "outputs": [],
      "source": [
        "web_chat.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_QG2S899BBJ"
      },
      "source": [
        "### 使用串流方式顯示輸出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SEXqmplBFw0"
      },
      "outputs": [],
      "source": [
        "hist = []\n",
        "web_chat = gr.Interface(\n",
        "    fn = chat_f,\n",
        "    inputs = ['text', 'text', 'checkbox'],\n",
        "    outputs = ['text']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU_McbmiBLvZ"
      },
      "outputs": [],
      "source": [
        "web_chat.queue()\n",
        "web_chat.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "570S8JdhBksT"
      },
      "outputs": [],
      "source": [
        "web_chat.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hyVgEil9Fz8"
      },
      "source": [
        "利用包裝函式組合片段內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dIxREtO1AZm"
      },
      "outputs": [],
      "source": [
        "def wrapper_chat(sys_msg, user_msg, stream):\n",
        "    reply = ''\n",
        "    for chunk in chat_f(sys_msg, user_msg, stream):\n",
        "        reply += chunk\n",
        "        yield reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig1c9U2S1WVF"
      },
      "outputs": [],
      "source": [
        "hist = []\n",
        "web_chat = gr.Interface(\n",
        "    fn = wrapper_chat,\n",
        "    inputs = ['text', 'text', 'checkbox'],\n",
        "    outputs = ['text']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc_o6p5A1cQa"
      },
      "outputs": [],
      "source": [
        "web_chat.queue()\n",
        "web_chat.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muY9Tmas5Sfc"
      },
      "outputs": [],
      "source": [
        "web_chat.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bZly9TQ9N8v"
      },
      "source": [
        "### 客製使用者介面"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BndzGRcl2k_7"
      },
      "outputs": [],
      "source": [
        "messages = []\n",
        "\n",
        "def wrapper_chat_bot(sys_msg, user_msg, stream):\n",
        "    messages.append([user_msg, ''])\n",
        "    for chunk in chat_f(sys_msg, user_msg, stream):\n",
        "        messages[-1][1] += chunk\n",
        "        yield messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5fVguj03bWg"
      },
      "outputs": [],
      "source": [
        "web_chat = gr.Interface(\n",
        "    fn=wrapper_chat_bot,\n",
        "    inputs=[\n",
        "        gr.Textbox(label='系統角色', value='使用繁體中文的小助理'),\n",
        "        gr.Textbox(label='使用者發言'),\n",
        "        gr.Checkbox(label='使用串流', value=False)],\n",
        "    outputs=[gr.Chatbot(label='AI 回覆')]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLqvX5Bu4R99"
      },
      "outputs": [],
      "source": [
        "hist = []\n",
        "web_chat.queue()\n",
        "web_chat.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP-v3wby4pDG"
      },
      "outputs": [],
      "source": [
        "web_chat.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn6ELd1-KV4B"
      },
      "outputs": [],
      "source": [
        "def txt_to_img_md(prompt):\n",
        "    return f'![{prompt}]({txt_to_img_url(prompt)})'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUEQYL5GEOKp"
      },
      "outputs": [],
      "source": [
        "tools_table.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSccxr-WLv6B"
      },
      "outputs": [],
      "source": [
        "tools_table.append({      # 每個元素代表一個函式\n",
        "    \"chain\": False,  # 生圖後不需要傳回給 API\n",
        "    \"func\": txt_to_img_md,\n",
        "    \"spec\": {        # function calling 需要的函式規格\n",
        "        'type': 'function',\n",
        "        'function': {\n",
        "            \"name\": \"txt_to_img_md\",\n",
        "            \"description\": \"可由文字生圖並傳回 markdown 圖像元素\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"prompt\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"描述要產生圖像內容的文字\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"prompt\"],\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDD3T9_xMCSN"
      },
      "outputs": [],
      "source": [
        "hist = []\n",
        "messages = []\n",
        "web_chat = gr.Interface(\n",
        "    fn=wrapper_chat_bot,\n",
        "    inputs=[\n",
        "        gr.Textbox(label='系統角色', value='使用繁體中文的小助理'),\n",
        "        gr.Textbox(label='使用者發言'),\n",
        "        gr.Checkbox(label='使用串流', value=False)],\n",
        "    outputs=[gr.Chatbot(label='AI 回覆')]\n",
        ")\n",
        "\n",
        "web_chat.queue()\n",
        "web_chat.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKI8uZIKdQgU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flo93iUQND4-"
      },
      "outputs": [],
      "source": [
        "web_chat.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}