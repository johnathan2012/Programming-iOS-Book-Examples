{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnathan2012/Programming-iOS-Book-Examples/blob/master/GPT4Dev_ch03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 API 參數解析與錯誤處理"
      ],
      "metadata": {
        "id": "AG7gBKUV92Bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-1 事前準備\n",
        "\n",
        "安裝必要的套件與匯入相關模組後建立用戶端物件"
      ],
      "metadata": {
        "id": "ccVUpuXM9dRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install rich\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "from rich import print as pprint\n",
        "client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "Dd2tbXUFAMgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-2 控制生成訊息與 token 數量"
      ],
      "metadata": {
        "id": "v1-ga-Tyw5Ou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 指定生成的訊息數量 - n"
      ],
      "metadata": {
        "id": "ODW5sx_XMSYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"你好\"}],\n",
        "  n=2\n",
        ")\n",
        "\n",
        "pprint(reply)\n",
        "\n",
        "for choice in reply.choices:\n",
        "    print(choice.index, choice.message.content)"
      ],
      "metadata": {
        "id": "kRgJDzMUilrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 設定詞彙黑名單 - stop"
      ],
      "metadata": {
        "id": "RqbMN9POMUkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"你好\"}],\n",
        "  stop=['好']\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)\n",
        "print(reply.choices[0].finish_reason)"
      ],
      "metadata": {
        "id": "yXJqNS3fjRZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 設定回覆語句的 tokens 數量上限 - max_tokens"
      ],
      "metadata": {
        "id": "1KUb_1ELLvyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"您好!\"}\n",
        "    ],\n",
        "    max_tokens = 5\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)\n",
        "print(reply.choices[0].finish_reason)\n",
        "print(reply.usage.completion_tokens)"
      ],
      "metadata": {
        "id": "EPrrVXy2Pf6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken\n",
        "encoder = tiktoken.encoding_for_model('gpt-3.5-turbo')"
      ],
      "metadata": {
        "id": "ADzh725yf96r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.encode(\"您好！有什\")"
      ],
      "metadata": {
        "id": "Lww8VuHe5TgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "超過模型限制的 tokens 數"
      ],
      "metadata": {
        "id": "TPQbUVh3L9tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo-1106\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"你好\"}\n",
        "    ],\n",
        "    max_tokens = 16380\n",
        ")"
      ],
      "metadata": {
        "id": "7L-Bvt2NHDcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-3 控制回覆內容的變化性"
      ],
      "metadata": {
        "id": "Bp3B7u-pw_qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 讓回覆更具彈性 - temperature"
      ],
      "metadata": {
        "id": "JQhZoMpINYAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"嗨！\"}],\n",
        "  temperature=0,\n",
        "  n=2\n",
        ")\n",
        "\n",
        "for choice in reply.choices:\n",
        "    print(choice.index, choice.message.content)"
      ],
      "metadata": {
        "id": "ECWZd8GUkIfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"嗨！\"}],\n",
        "  temperature=2,\n",
        "  n=2\n",
        ")\n",
        "\n",
        "for choice in reply.choices:\n",
        "    print(choice.index, choice.message.content)"
      ],
      "metadata": {
        "id": "xXAJhTiVkRYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 控制詞彙的豐富度 - top_p"
      ],
      "metadata": {
        "id": "JM6fYpXYJ4P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"嗨！\"}],\n",
        "  top_p=0,\n",
        "  n=2\n",
        ")\n",
        "\n",
        "for choice in reply.choices:\n",
        "    print(choice.index, choice.message.content)"
      ],
      "metadata": {
        "id": "ZC5i5Lt864EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 控制詞彙的重複性 - presence_penalty 與 frequency_penalty"
      ],
      "metadata": {
        "id": "0XwQ69fZNsDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"台北是什麼樣的城市？\"\n",
        "  }],\n",
        "  temperature=1,\n",
        "  presence_penalty=-2,\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ],
      "metadata": {
        "id": "L-yFTbubsROQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"台北是什麼樣的城市？\"\n",
        "  }],\n",
        "  temperature=1,\n",
        "  presence_penalty=2,\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ],
      "metadata": {
        "id": "ilf99zqz4B0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[{\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"台北是什麼樣的城市？\"}],\n",
        "  temperature=1,\n",
        "  frequency_penalty=-2,\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ],
      "metadata": {
        "id": "T_VmWcN66DDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[{\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"台北是什麼樣的城市？\"}],\n",
        "  temperature=1,\n",
        "  frequency_penalty=2,\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ],
      "metadata": {
        "id": "nnE5E1lu4EeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 調整特定 token 的分數 - logi-bias\n"
      ],
      "metadata": {
        "id": "lc2KqtIVKBeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.encode('你好')"
      ],
      "metadata": {
        "id": "Ecv9UTckKC0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"你好\"}],\n",
        "  temperature=1,\n",
        "  logit_bias={\n",
        "      53901: -100,\n",
        "      57668: -100\n",
        "  },\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ],
      "metadata": {
        "id": "wVKafC6IKGnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.encode('哈')"
      ],
      "metadata": {
        "id": "wfphuAh7KHA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"你好\"}],\n",
        "  temperature=1,\n",
        "  logit_bias={\n",
        "      99771: 100,\n",
        "  },\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ],
      "metadata": {
        "id": "KveBU5Qff6tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 固定可預測的輸出 - seed\n",
        "\n",
        "使用亂數種子固定輸出, 不保證, 自己要檢查回覆指紋。1106 的模型才提供。"
      ],
      "metadata": {
        "id": "EgsbCjDGJWJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replies = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-0613\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"請用兩句話介紹台北市\"\n",
        "  }],\n",
        "  seed=1\n",
        ")\n",
        "\n",
        "print(replies.system_fingerprint)\n",
        "print(replies.choices[0].message.content)"
      ],
      "metadata": {
        "id": "QPu-CP-5LYnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replies = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"請用兩句話介紹台北市\"\n",
        "  }],\n",
        "  seed=2\n",
        ")\n",
        "\n",
        "print(replies.system_fingerprint)\n",
        "print(replies.choices[0].message.content)"
      ],
      "metadata": {
        "id": "dRs8oH8qNjUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-4 串流輸出"
      ],
      "metadata": {
        "id": "9oBB8v9idNQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 可循序傳回結果的迭代器 (iterator) - stream\n"
      ],
      "metadata": {
        "id": "p-798ckrMcjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replies = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"你好\"\n",
        "  }],\n",
        "  stream=True,\n",
        ")\n",
        "\n",
        "for reply in replies:\n",
        "    pprint(reply)"
      ],
      "metadata": {
        "id": "UKOBD3_WdMIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replies = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"台北是什麼樣的城市？\"\n",
        "  }],\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for reply in replies:\n",
        "    print(reply.choices[0].delta.content or '', end='')"
      ],
      "metadata": {
        "id": "OSUKBv9hk9aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 串流多個語句"
      ],
      "metadata": {
        "id": "HNMaghUIMXjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replies = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"你好\"\n",
        "  }],\n",
        "  stream=True,\n",
        "  n=2\n",
        ")\n",
        "\n",
        "for reply in replies:\n",
        "    print(reply.choices[0].delta.content or '', end='')"
      ],
      "metadata": {
        "id": "IpvOB9g9MkaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3-5 進階控制"
      ],
      "metadata": {
        "id": "GYrRV0k1ga0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 控制輸出格式 - response_format\n"
      ],
      "metadata": {
        "id": "Lq6AgwlP9L-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo-1106\",\n",
        "    messages = [{\n",
        "        \"role\":\"user\",\n",
        "        \"content\": \"台灣最高的山高度是多少？\"\n",
        "                   \"請分別告訴我山名和高度\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ],
      "metadata": {
        "id": "Vs7Sa7yG9ORm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo-1106\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\",\n",
        "         \"content\": \"台灣最高的山高度是多少？\"\n",
        "         \"請分別告訴我山名和高度\"},\n",
        "        {\"role\":\"system\", \"content\": \"請用 json 格式回覆\"}\n",
        "    ],\n",
        "    response_format={'type': 'json_object'} # or 'text'\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ],
      "metadata": {
        "id": "kL3ax4Uz9s2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 取得底層 HTTP 回應內容"
      ],
      "metadata": {
        "id": "BblEBT0A5C-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 取得原始 HTTP 回覆內容\n",
        "reply = client.chat.completions.with_raw_response.create(\n",
        "    model = \"gpt-3.5-turbo-1106\",\n",
        "    # model = \"gpt-4\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"你好\"}\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "RXHwp-NY1EFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "print(reply.status_code)\n",
        "print('------')\n",
        "print(reply.text) # JSON 格式文字\n",
        "print('------')\n",
        "reply_dic = json.loads(reply.text) # 轉成 Python 字典\n",
        "pprint(reply_dic)"
      ],
      "metadata": {
        "id": "3lxlCxYz1K1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    # model = \"gpt-4\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"你好\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "pprint(reply.model_dump())"
      ],
      "metadata": {
        "id": "6Fnz9WeyKQLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 有眼睛的模型 - gpt-4-vision (GPT-4V)"
      ],
      "metadata": {
        "id": "tinUei5sXLh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4-vision-preview\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"圖片裡有什麼？\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://flagtech.github.io/F3762/\"\n",
        "                               \"images/cat1.jpg\",\n",
        "                        'detail': 'high'\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=1000,\n",
        ")\n",
        "\n",
        "pprint(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "_TB7TsFdXRnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "r = requests.get(\n",
        "    'https://flagtech.github.io/F3762/images/cat2.jpg'\n",
        ")\n",
        "\n",
        "with open('cat2.jpg', 'wb') as f:\n",
        "    f.write(r.content)"
      ],
      "metadata": {
        "id": "1C-70pKZHpJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')"
      ],
      "metadata": {
        "id": "OQXov1_OcDZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = encode_image('cat2.jpg')\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4-vision-preview\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"圖片裡有什麼？\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{img}\",\n",
        "                        'detail': 'high'\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "pNs9jSuKbxPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4-vision-preview\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"這些圖片裡相同的是什麼？\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://flagtech.github.io/F3762/\"\n",
        "                               \"images/cat1.jpg\",\n",
        "                        'detail': 'high'\n",
        "                    },\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://flagtech.github.io/F3762/\"\n",
        "                               \"images/cat2.jpg\",\n",
        "                        'detail': 'high'\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=1000,\n",
        ")\n",
        "\n",
        "pprint(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "qv9i3ceLOuSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-5 錯誤處理與使用限制"
      ],
      "metadata": {
        "id": "MzbgDbQCMInK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Exception\n",
        "+--OpenAIError\n",
        "   +--APIError ◆ message: str\n",
        "      |      ◆ request: httpx.Request\n",
        "      +--APIResponseValidationError ◆ response: httpx.Response\n",
        "      |  (回覆內容格式有誤)            ◆ status_code: int\n",
        "      +--APIStatusError ◆ response: httpx.Response\n",
        "      |  |            ◆ status_code: int\n",
        "      |  +--BadRequestError (請求參數或是格式錯誤)\n",
        "      |  +--AuthenticationError (金鑰認證有問題)\n",
        "      |  +--PermissionDeniedError\n",
        "      |  +--NotFoundError\n",
        "      |  +--ConflictError\n",
        "      |  +--UnprocessableEntityError\n",
        "      |  +--RateLimitError (超過次數限制)\n",
        "      |  +--InternalServerError\n",
        "      +--APIConnectionError (無法連線)\n",
        "         +--APITimeoutError (連線逾時)\n",
        "'''"
      ],
      "metadata": {
        "id": "28kEhkf5RTJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用例外機制處理錯誤"
      ],
      "metadata": {
        "id": "1bV1BZvzMF06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    reply = client.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo-1106\",\n",
        "        messages = [\n",
        "            {\"role\":\"user\", \"content\": \"你好\"}\n",
        "        ],\n",
        "        max_tokens = 20000\n",
        "    )\n",
        "    print(reply.choices[0].message.content)\n",
        "\n",
        "except openai.APIError as err:\n",
        "    print(err.message)"
      ],
      "metadata": {
        "id": "fBmSX7n1KsDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    reply = client.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo-1106\",\n",
        "        messages = [\n",
        "            {\"role\":\"user\", \"content\": \"你好\"}\n",
        "        ],\n",
        "        max_tokens = 20000\n",
        "    )\n",
        "    print(reply.choices[0].message.content)\n",
        "\n",
        "except openai.APIStatusError as err:\n",
        "    err_json = err.response.json()\n",
        "    print(f\"錯誤類型：{err_json['error']['type']}\")\n",
        "    print(f\"錯誤碼：{err_json['error']['code']}\")\n",
        "    print(f\"錯誤訊息：{err_json['error']['message']}\")"
      ],
      "metadata": {
        "id": "l4YlKKlPszBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eOyPzdCRs66r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}