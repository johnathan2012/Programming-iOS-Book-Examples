{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnathan2012/Programming-iOS-Book-Examples/blob/master/GPT4Dev_ch07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNYngg3YPEp5"
      },
      "source": [
        "# 7 網頁版聊天程式與文字生圖 Image API"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7-1 準備工作\n"
      ],
      "metadata": {
        "id": "qdQ33kiZ4Gmg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccVUpuXM9dRz"
      },
      "source": [
        "**準備工作**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1CAsaxl9_v4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61abbecb-00ea-428e-fe0d-eae19994de75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.21.0-py3-none-any.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.12.0 (from gradio)\n",
            "  Downloading gradio_client-0.12.0-py3-none-any.whl (310 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.3.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.10.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.28.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.12.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.12.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=6b116ad857b783af6aa403911010909964861b534d464808caa99df1733cbfc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 colorama-0.4.6 fastapi-0.110.0 ffmpy-0.3.2 gradio-4.21.0 gradio-client-0.12.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 orjson-3.9.15 pydub-0.25.1 python-multipart-0.0.9 ruff-0.3.2 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tomlkit-0.12.0 uvicorn-0.28.0 websockets-11.0.3\n",
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-1.13.3\n",
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch-python-1.2.3.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (4.12.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2024.2.2)\n",
            "Building wheels for collected packages: googlesearch-python\n",
            "  Building wheel for googlesearch-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googlesearch-python: filename=googlesearch_python-1.2.3-py3-none-any.whl size=4209 sha256=b41d5a529d752883f4ef9d84d49709429f5ed590c5ba7217a9653a8f8a53a22a\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/24/e9/6c225502948c629b01cc895f86406819281ef0da385f3eb669\n",
            "Successfully built googlesearch-python\n",
            "Installing collected packages: googlesearch-python\n",
            "Successfully installed googlesearch-python-1.2.3\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "!pip install openai\n",
        "!pip install googlesearch-python\n",
        "!pip install rich\n",
        "from rich import print as pprint\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**從 github 下載套件**"
      ],
      "metadata": {
        "id": "7fb60E5MvUYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/FlagTech/flagchat4.git flagchat4"
      ],
      "metadata": {
        "id": "Z3Dw2PpubJnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83a51fe-4605-41b2-bc9f-bf2d9092465c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'flagchat4'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 27 (delta 7), reused 27 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (27/27), 8.94 KiB | 8.94 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**匯入相關函式與資料**"
      ],
      "metadata": {
        "id": "EN00RCpFvXWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flagchat4 import (\n",
        "    set_client,       # 設定要使用的用戶端物件 (預設直接使用 openai 模組)\n",
        "    get_reply,        # 輸入訊息串列傳回回覆\n",
        "    chat,             # 輸入 system, user 發言取得回覆並會記錄對答歷史\n",
        "    tools_table,      # 記錄可用工具函式的參考表, 預設有 Google 搜尋函式\n",
        "    set_backtrace,    # 設定記錄幾組對答 (預設：2)\n",
        "    empty_history,    # 清除對答歷史\n",
        ")"
      ],
      "metadata": {
        "id": "HuPwhogybOJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_client(client)"
      ],
      "metadata": {
        "id": "FgdIwjP1pB1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用方法可參考 [Colab 範例筆記本](https://colab.research.google.com/drive/1TvZ6Bpv8NQvz9woIFJX5yhlU517-zBRK?usp=sharing)"
      ],
      "metadata": {
        "id": "I2xth-wFu_re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in chat('繁體中文小助手', '2023 金馬獎最佳女配角'):\n",
        "    print(chunk, end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P7FPzXUqINk",
        "outputId": "c775cc3d-c347-4d1a-ad43-cba1f80e210b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "嘗試叫用：google_res(**{'user_msg': '2023 \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n金馬獎 \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n采才\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n最佳女配角'})\n",
            "The winner of the \"Best Supporting Actress\" award at the 2023 Golden Horse Awards is Fang Zhiyou for the film \"Day Off\" (《本日公休》)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7-2 使用 gradio 套件快速建立網頁程式"
      ],
      "metadata": {
        "id": "P0o41v7E4Ka1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 安裝與使用 gradio"
      ],
      "metadata": {
        "id": "fdxBFtLh83QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 已經在第一個儲存格安裝過\n",
        "# 目前要先安裝 gradio, 在安裝 openai 套件才不會有問題\n",
        "# !pip install gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "CBotGWq1rH6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立基本的網頁介面"
      ],
      "metadata": {
        "id": "jmBZZNCU88us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat = gr.Interface(\n",
        "    fn = chat,\n",
        "    inputs = ['text', 'text'],\n",
        "    outputs = ['text']\n",
        ")"
      ],
      "metadata": {
        "id": "fRkqv4VGrgYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.queue()\n",
        "web_chat.launch(share=True)"
      ],
      "metadata": {
        "id": "6-kRoO1JsGq2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "8445075d-02d4-4515-9c9e-49a0f65c3524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://5692e09eb71801f9a4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5692e09eb71801f9a4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.close()"
      ],
      "metadata": {
        "id": "u30T026Tshcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefc61f3-f8e7-4d2e-8083-9f07abfae97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用串流方式顯示輸出"
      ],
      "metadata": {
        "id": "h_QG2S899BBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat = gr.Interface(\n",
        "    fn = chat,\n",
        "    inputs = ['text', 'text', 'checkbox'],\n",
        "    outputs = ['text']\n",
        ")"
      ],
      "metadata": {
        "id": "4SEXqmplBFw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.queue()\n",
        "web_chat.launch()"
      ],
      "metadata": {
        "id": "gU_McbmiBLvZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "f6dedafd-7aab-4f3a-ad39-92f220ab6895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://cf57f7ab9d849f04bd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cf57f7ab9d849f04bd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.close()"
      ],
      "metadata": {
        "id": "570S8JdhBksT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a18905c1-c56c-45ef-c600-e18836a17fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "利用包裝函式組合片段內容"
      ],
      "metadata": {
        "id": "3hyVgEil9Fz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wrapper_chat(sys_msg, user_msg, stream):\n",
        "    reply = ''\n",
        "    for chunk in chat(sys_msg, user_msg, stream):\n",
        "        reply += chunk\n",
        "        yield reply"
      ],
      "metadata": {
        "id": "-dIxREtO1AZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat = gr.Interface(\n",
        "    fn = wrapper_chat,\n",
        "    inputs = ['text', 'text', 'checkbox'],\n",
        "    outputs = ['text']\n",
        ")"
      ],
      "metadata": {
        "id": "ig1c9U2S1WVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.queue()\n",
        "web_chat.launch()"
      ],
      "metadata": {
        "id": "uc_o6p5A1cQa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "a89a9ddd-042e-45e3-883a-2f4070b42a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d6268dd073bd797147.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d6268dd073bd797147.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq97FfZgvyMu",
        "outputId": "b67b4971-f5b1-4e4a-e188-589aba287419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 客製使用者介面"
      ],
      "metadata": {
        "id": "6bZly9TQ9N8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "\n",
        "def wrapper_chat_bot(sys_msg, user_msg, stream):\n",
        "    messages.append([user_msg, ''])\n",
        "    for chunk in chat(sys_msg, user_msg, stream):\n",
        "        messages[-1][1] += chunk\n",
        "        yield messages"
      ],
      "metadata": {
        "id": "BndzGRcl2k_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat = gr.Interface(\n",
        "    fn=wrapper_chat_bot,\n",
        "    inputs=[\n",
        "        gr.Textbox(label='系統角色', value='使用繁體中文的小助理'),\n",
        "        gr.Textbox(label='使用者發言'),\n",
        "        gr.Checkbox(label='使用串流', value=False)],\n",
        "    outputs=[gr.Chatbot(label='AI 回覆')]\n",
        ")"
      ],
      "metadata": {
        "id": "A5fVguj03bWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.queue()\n",
        "web_chat.launch()"
      ],
      "metadata": {
        "id": "lLqvX5Bu4R99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "5d9da667-8524-463a-d2ea-f0c0514fa149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://74c505e0ae276c6939.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://74c505e0ae276c6939.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.close()"
      ],
      "metadata": {
        "id": "oP-v3wby4pDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fab2d3-4829-4d71-fa52-b9ac9d9a7152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[連結文字](https://)## 7-3 使用 DALL‧E 的 Image API"
      ],
      "metadata": {
        "id": "OA5OOLjP4Q0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7-3 使用 DALL‧E 的 Image API"
      ],
      "metadata": {
        "id": "BwYEvJb9uTR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image API 用法"
      ],
      "metadata": {
        "id": "G5NzRvvK80h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.images.generate(   # 文字生圖\n",
        "    model='dall-e-3',\n",
        "    prompt='夕陽下駛過海邊的火車', # 描述文字\n",
        "    n=1,                        # 生圖張數\n",
        "    quality='hd',\n",
        "    size='1024x1024',           # 影像大小, 預設 1024x1024\n",
        "    style='natural',            # 風格, 預設 'vivid'\n",
        ")\n",
        "pprint(res)"
      ],
      "metadata": {
        "id": "UsJq8Hlw-fWT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ff1bdefe-69a9-425d-c912-4598995e2cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mImagesResponse\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1710124919\u001b[0m,\n",
              "    \u001b[33mdata\u001b[0m=\u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mImage\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mb64_json\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "            \u001b[33mrevised_prompt\u001b[0m=\u001b[32m'A train traveling along the coastline, perfectly silhouetted against the breathtaking \u001b[0m\n",
              "\u001b[32mdisplay of a sunset. The setting sun casts a beautiful shade of red and orange across the sky, reflecting \u001b[0m\n",
              "\u001b[32mbrilliantly off the tranquil ocean. Coastal scenery accompanies the railroad, teeming with seagulls and waves \u001b[0m\n",
              "\u001b[32mgently crashing onto the sands. The train, in motion, lends a sense of adventure to this tranquil scene.'\u001b[0m,\n",
              "            \u001b[33murl\u001b[0m=\u001b[32m'https://oaidalleapiprodscus.blob.core.windows.net/private/org-TnN5jDJWh2Gbe6gZ6C11q1fl/user-hwS8wM\u001b[0m\n",
              "\u001b[32mY6Z8ZzjiE3tcFcl4mM/img-L0vqXRxWLeFOGPj2N3Tv8RVn.png?\u001b[0m\u001b[32mst\u001b[0m\u001b[32m=\u001b[0m\u001b[32m2024\u001b[0m\u001b[32m-03-11T01%3A41%3A59Z&\u001b[0m\u001b[32mse\u001b[0m\u001b[32m=\u001b[0m\u001b[32m2024\u001b[0m\u001b[32m-03-11T03%3A41%3A59Z&\u001b[0m\u001b[32msp\u001b[0m\u001b[32m=\u001b[0m\u001b[32mr\u001b[0m\u001b[32m&\u001b[0m\u001b[32msv\u001b[0m\n",
              "\u001b[32m=\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m-08-06&\u001b[0m\u001b[32msr\u001b[0m\u001b[32m=\u001b[0m\u001b[32mb\u001b[0m\u001b[32m&\u001b[0m\u001b[32mrscd\u001b[0m\u001b[32m=\u001b[0m\u001b[32minline\u001b[0m\u001b[32m&\u001b[0m\u001b[32mrsct\u001b[0m\u001b[32m=\u001b[0m\u001b[32mimage\u001b[0m\u001b[32m/png&\u001b[0m\u001b[32mskoid\u001b[0m\u001b[32m=\u001b[0m\u001b[32m6aaadede\u001b[0m\u001b[32m-4fb3-4698-a8f6-684d7786b067&\u001b[0m\u001b[32msktid\u001b[0m\u001b[32m=\u001b[0m\u001b[32ma48cca56\u001b[0m\u001b[32m-e6da-484e-a81\u001b[0m\n",
              "\u001b[32m4-9c849652bcb3&\u001b[0m\u001b[32mskt\u001b[0m\u001b[32m=\u001b[0m\u001b[32m2024\u001b[0m\u001b[32m-03-10T20%3A49%3A48Z&\u001b[0m\u001b[32mske\u001b[0m\u001b[32m=\u001b[0m\u001b[32m2024\u001b[0m\u001b[32m-03-11T20%3A49%3A48Z&\u001b[0m\u001b[32msks\u001b[0m\u001b[32m=\u001b[0m\u001b[32mb\u001b[0m\u001b[32m&\u001b[0m\u001b[32mskv\u001b[0m\u001b[32m=\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m-08-06&\u001b[0m\u001b[32msig\u001b[0m\u001b[32m=\u001b[0m\u001b[32myYwzIKUZJEoFWXlsh\u001b[0m\n",
              "\u001b[32mPh70TZpwPZGJaqFvLGgbI7S\u001b[0m\u001b[32m/So%3D'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ImagesResponse</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1710124919</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">data</span>=<span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Image</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">b64_json</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">revised_prompt</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'A train traveling along the coastline, perfectly silhouetted against the breathtaking </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">display of a sunset. The setting sun casts a beautiful shade of red and orange across the sky, reflecting </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">brilliantly off the tranquil ocean. Coastal scenery accompanies the railroad, teeming with seagulls and waves </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">gently crashing onto the sands. The train, in motion, lends a sense of adventure to this tranquil scene.'</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://oaidalleapiprodscus.blob.core.windows.net/private/org-TnN5jDJWh2Gbe6gZ6C11q1fl/user-hwS8wM</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Y6Z8ZzjiE3tcFcl4mM/img-L0vqXRxWLeFOGPj2N3Tv8RVn.png?st=2024-03-11T01%3A41%3A59Z&amp;se=2024-03-11T03%3A41%3A59Z&amp;sp=r&amp;sv</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">=2021-08-06&amp;sr=b&amp;rscd=inline&amp;rsct=image/png&amp;skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&amp;sktid=a48cca56-e6da-484e-a81</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">4-9c849652bcb3&amp;skt=2024-03-10T20%3A49%3A48Z&amp;ske=2024-03-11T20%3A49%3A48Z&amp;sks=b&amp;skv=2021-08-06&amp;sig=yYwzIKUZJEoFWXlsh</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Ph70TZpwPZGJaqFvLGgbI7S/So%3D'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 建立文字生圖像網址的函式"
      ],
      "metadata": {
        "id": "m9ZE2kKWXrxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def txt_to_img_url(prompt):\n",
        "    response = client.images.generate(\n",
        "        model='dall-e-3',\n",
        "        prompt=prompt,\n",
        "        n=1,\n",
        "        size='1024x1024',\n",
        "        style='vivid',\n",
        "        quality='hd'\n",
        "    )\n",
        "    return response.data[0].url"
      ],
      "metadata": {
        "id": "ge1xqcrCBeWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(txt_to_img_url('田邊騎著腳踏車晃的少年'))"
      ],
      "metadata": {
        "id": "OogZKOJ9B3f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b97c6ac-9485-4aa7-fcd9-c1a6bafd078d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://oaidalleapiprodscus.blob.core.windows.net/private/org-TnN5jDJWh2Gbe6gZ6C11q1fl/user-hwS8wMY6Z8ZzjiE3tcFcl4mM/img-1pUmu17WXOXEz7OqJdmEmN02.png?st=2024-03-11T01%3A42%3A19Z&se=2024-03-11T03%3A42%3A19Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-10T18%3A23%3A23Z&ske=2024-03-11T18%3A23%3A23Z&sks=b&skv=2021-08-06&sig=xlq2Xq%2BB7liM7FmQZN6BA6PyNi88GwtbssnGWWsvH2c%3D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools_table.append(\n",
        "    {                    # 每個元素代表一個函式\n",
        "        \"chain\": False,  # 生圖後不需要傳回給 API\n",
        "        \"func\": txt_to_img_url,\n",
        "        \"spec\": {        # function calling 需要的函式規格\n",
        "            'type': 'function',\n",
        "            'function': {\n",
        "                \"name\": \"txt_to_img_url\",\n",
        "                \"description\": \"可由文字生圖並傳回圖像網址\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"prompt\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"描述要產生圖像內容的文字\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"prompt\"],\n",
        "                },\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "wh0CFGhiC07Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in chat('小助理', '我想要夕陽下海豚躍出海面的圖像', True):\n",
        "    print(chunk)"
      ],
      "metadata": {
        "id": "Q42dWiLwDvNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21895474-f1b0-487c-da71-dff34d679fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "嘗試叫用：txt_to_img_url(**{'prompt': 'dolphins leaping out of the ocean at sunset'})\n",
            "https://oaidalleapiprodscus.blob.core.windows.net/private/org-TnN5jDJWh2Gbe6gZ6C11q1fl/user-hwS8wMY6Z8ZzjiE3tcFcl4mM/img-UdIryHrIQhRAoIGtwiCxn4Or.png?st=2024-03-11T01%3A42%3A48Z&se=2024-03-11T03%3A42%3A48Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-10T18%3A32%3A49Z&ske=2024-03-11T18%3A32%3A49Z&sks=b&skv=2021-08-06&sig=t9gjbFaPJX9XupFHtDLZG3igR6zNXOnCdewhcis5hf0%3D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "套用生圖功能到網頁聊天中"
      ],
      "metadata": {
        "id": "HaYtdEdEKZ-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "\n",
        "def wrapper_chat_bot(sys_msg, user_msg, stream):\n",
        "    messages.append([user_msg, ''])\n",
        "    for chunk in chat(sys_msg, user_msg, stream):\n",
        "        messages[-1][1] += chunk\n",
        "        yield messages\n",
        "\n",
        "web_chat = gr.Interface(\n",
        "    fn=wrapper_chat_bot,\n",
        "    inputs=[\n",
        "        gr.Textbox(label='系統角色', value='使用繁體中文的小助理'),\n",
        "        gr.Textbox(label='使用者發言'),\n",
        "        gr.Checkbox(label='使用串流', value=False)],\n",
        "    outputs=[gr.Chatbot(label='AI 回覆')]\n",
        ")\n",
        "\n",
        "web_chat.queue()\n",
        "web_chat.launch()"
      ],
      "metadata": {
        "id": "Xn9BIkvjJxtL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "00820536-9818-4084-b201-8493fbb82c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://309a1992ec431c1b10.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://309a1992ec431c1b10.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果只會顯示連結, 對於 Chatbot 介面要提供 Mardown 格式才會顯示。"
      ],
      "metadata": {
        "id": "CtVG7aqhKgF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.close()"
      ],
      "metadata": {
        "id": "Y1z5C4ghNS53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e92d3d-d866-4f5b-d3cd-59c397cab427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 包裝成生成 markdown 語法的函式\n"
      ],
      "metadata": {
        "id": "a3FlFSI6KqN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def txt_to_img_md(prompt):\n",
        "    return f'![{prompt}]({txt_to_img_url(prompt)})'"
      ],
      "metadata": {
        "id": "Pn6ELd1-KV4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools_table.pop()\n",
        "tools_table.append({      # 每個元素代表一個函式\n",
        "    \"chain\": False,  # 生圖後不需要傳回給 API\n",
        "    \"func\": txt_to_img_md,\n",
        "    \"spec\": {        # function calling 需要的函式規格\n",
        "        'type': 'function',\n",
        "        'function': {\n",
        "            \"name\": \"txt_to_img_md\",\n",
        "            \"description\": \"可由文字生圖並傳回 markdown 圖像元素\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"prompt\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"描述要產生圖像內容的文字\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"prompt\"],\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "})"
      ],
      "metadata": {
        "id": "PSccxr-WLv6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "\n",
        "def wrapper_chat_bot(sys_msg, user_msg, stream):\n",
        "    messages.append([user_msg, ''])\n",
        "    for chunk in chat(sys_msg, user_msg, stream):\n",
        "        messages[-1][1] += chunk\n",
        "        yield messages\n",
        "\n",
        "web_chat = gr.Interface(\n",
        "    fn=wrapper_chat_bot,\n",
        "    inputs=[\n",
        "        gr.Textbox(label='系統角色', value='使用繁體中文的小助理'),\n",
        "        gr.Textbox(label='使用者發言'),\n",
        "        gr.Checkbox(label='使用串流', value=False)],\n",
        "    outputs=[gr.Chatbot(label='AI 回覆')]\n",
        ")\n",
        "\n",
        "web_chat.queue()\n",
        "web_chat.launch()"
      ],
      "metadata": {
        "id": "WDD3T9_xMCSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.close()"
      ],
      "metadata": {
        "id": "Flo93iUQND4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d021b9-5d44-4239-ae96-31924690712a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "\n",
        "def wrapper_chat_bot(sys_msg, user_msg, stream, model):\n",
        "    messages.append([user_msg, ''])\n",
        "    for chunk in chat(sys_msg, user_msg, stream, model=model):\n",
        "        messages[-1][1] += chunk\n",
        "        yield messages\n",
        "\n",
        "web_chat = gr.Interface(\n",
        "    fn=wrapper_chat_bot,\n",
        "    inputs=[\n",
        "        gr.Textbox(label='系統角色', value='使用繁體中文的小助理'),\n",
        "        gr.Textbox(label='使用者發言'),\n",
        "        gr.Checkbox(label='使用串流', value=False),\n",
        "        gr.Radio(label='模型', choices=['gpt-3.5-turbo-1106',\n",
        "                                       'gpt-4-1106-preview'],\n",
        "                 value='gpt-4-1106-preview')],\n",
        "    outputs=[gr.Chatbot(label='AI 回覆')]\n",
        ")\n",
        "\n",
        "web_chat.queue()\n",
        "web_chat.launch()"
      ],
      "metadata": {
        "id": "m6aiXt1W_Fkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "8108c914-a68b-4e41-8172-d8d10a9f62f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d5c46c86834125773e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d5c46c86834125773e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "web_chat.close()"
      ],
      "metadata": {
        "id": "LdM6anxxAE0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d79e48-8a5e-4b45-e017-9636ff5f7bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}