{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnathan2012/Programming-iOS-Book-Examples/blob/master/flagchat4_usage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeP8gN6eQZqo"
      },
      "source": [
        "# flagchat4 套件用法示範"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR-iKM00WuGE"
      },
      "source": [
        "本套件主要將 OpenAI Chat API 抽象化, 納入串流、function calling 功能, 並且將介面統一使用生成器產生回覆, 不論是否啟用串流模式, 都可用一致的方式取得回覆。另外, 也搭配 function calling 設計一個簡易的外掛系統。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHfPJ7Y7QfaG"
      },
      "source": [
        "## 事前準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1CAsaxl9_v4",
        "outputId": "bfd8415c-4667-408f-9182-a077cf796727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/221.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7\n",
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch-python-1.2.3.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (4.11.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2023.11.17)\n",
            "Building wheels for collected packages: googlesearch-python\n",
            "  Building wheel for googlesearch-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googlesearch-python: filename=googlesearch_python-1.2.3-py3-none-any.whl size=4209 sha256=d2cd613d52284bc7c2b698eabd2656e696b2d17c4b92f832bee299252ef95102\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/24/e9/6c225502948c629b01cc895f86406819281ef0da385f3eb669\n",
            "Successfully built googlesearch-python\n",
            "Installing collected packages: googlesearch-python\n",
            "Successfully installed googlesearch-python-1.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install googlesearch-python\n",
        "from googlesearch import search\n",
        "from google.colab import userdata\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JmHgsP-Qm56"
      },
      "source": [
        "## 下載套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2q3m6rtPvo4",
        "outputId": "87c7432f-587a-4e36-c92d-a766627f7166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'flagchat4'...\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "git clone https://github.com/FlagTech/flagchat4.git flagchat4\n",
        "cd flagchat4/\n",
        "git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLXdCEVzQtSO"
      },
      "source": [
        "## 從模組匯入工具函式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPp3JjAuImG7"
      },
      "outputs": [],
      "source": [
        "from flagchat4 import (\n",
        "    set_client,       # 設定要使用的用戶端物件 (預設直接使用 openai 模組)\n",
        "    get_reply,        # 輸入訊息串列傳回回覆\n",
        "    chat,             # 輸入 system, user 發言取得回覆並會記錄對答歷史\n",
        "    tools_table,      # 記錄可用工具函式的參考表, 預設有 Google 搜尋函式\n",
        "    set_backtrace,    # 設定記錄幾組對答 (預設：2)\n",
        "    empty_history,    # 清除對答歷史\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "flagchat4 預設為直接使用 openai 模組當用戶端物件, 你也可以透過 `set_client` 函式設定客製的用戶端物件。"
      ],
      "metadata": {
        "id": "IIJ5LfKGe0_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 預設使用環境變數 OPENAI_API_KEY\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# 也可以使用客製的用戶端物件\n",
        "# client = openai.OpenAI(userdata.get('OPENAI_API_KEY'))\n",
        "# set_client(client)"
      ],
      "metadata": {
        "id": "Y5h3e7JkLPKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_backtrace(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxohD0nO0ptc",
        "outputId": "02f09ec6-8223-4e74-c256-fb0ff714b6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBMPPP5aQRE-"
      },
      "source": [
        "## 單一問答測試\n",
        "\n",
        "get_reply 可以會透過 function calling 機制使用 func_table 傳入的函式表格傳回回覆。模組內預設的 tools_table 只有 Google 搜尋函式。\n",
        "\n",
        "```python\n",
        "get_reply(\n",
        "    messages, # 訊息串列\n",
        "    stream=False # 是否啟用串流模式\n",
        "    tools_table=None # 工具函式參考表\n",
        ")\n",
        "```\n",
        "另外有選用的參數：\n",
        "\n",
        "```python\n",
        "model='gpt-3.5-turbo' # 指定模型\n",
        "debug=False # 是否要顯示除錯訊息, 包含訊息串列內容\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLO76nV4Ealo",
        "outputId": "00efac55-4048-4f69-83f7-f0216e828afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "嘗試叫用：google_res(**{'user_msg': '2023金馬獎最佳男配角'})\n",
            "2023年金馬獎最佳男配角的得主是陳慕義，他因在電影《老狐狸》中的表現獲此殊榮。\n"
          ]
        }
      ],
      "source": [
        "# 測試非串流方式 function_calling 功能\n",
        "for chunk in get_reply(       # 不論是否串流回覆, 都以生成器統一函式介面\n",
        "    [{\"role\":\"user\", \"content\":\"2023 金馬獎最佳男配角？\"}], # 訊息串列\n",
        "    tools_table=tools_table): # 工具函式表\n",
        "    print(chunk)              # 非串流模式只會生成一次"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNioKT6Vodaf",
        "outputId": "dc741309-51db-4dfd-9638-d0c65f33fec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "嘗試叫用：google_res(**{'user_msg': '2023金馬獎最佳導演'})\n",
            "根據上述的搜尋結果摘要，2023年金馬獎最佳導演得主是《老狐狸》的蕭雅全。"
          ]
        }
      ],
      "source": [
        "# 測試串流方式 function_calling 功能\n",
        "for chunk in get_reply(   # 不論是否串流回覆, 都以生成器統一函式介面\n",
        "    [{\"role\":\"user\", \"content\":\"2023 金馬獎最佳女配角？\"}], # 訊息串列\n",
        "    stream=True,              # 啟用串流模式\n",
        "    tools_table=tools_table): # 工具函式表\n",
        "    print(chunk, end='')  # 串流方式每次生成片段, 不換行才能接續內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m23Ds5BOtVnS",
        "outputId": "5bd55f56-31f2-4e8f-9563-344ace466cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "很抱歉，我無法提供當前或實時的數據信息，包括最新的獎項得主。截至我知识更新的時間在2023年之前，因此我沒有這一年度最佳導演獎的結果。要獲得最新的信息，建議查看最近的電影獎項結果，例如奧斯卡獎（Academy Awards）、金球獎（Golden Globe Awards）或其他電影節獎項的官方網站或可靠新聞來源。\n"
          ]
        }
      ],
      "source": [
        "# 測試非串流、無 function calling 功能\n",
        "for chunk in get_reply(\n",
        "    [{\"role\":\"user\", \"content\":\"2023 金馬獎最佳導演是誰？\"}]):\n",
        "    print(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay2vtRj3td6q",
        "outputId": "91a133d0-b9f9-4f6d-c630-71ae1350b5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "很抱歉，我無法提供即時信息或最新事件的更新，因為我的知識截止日期是2023年的初期。關於2023年金馬獎影帝的獲獎者，您可能需要查閱最新的新聞報導或官方金馬獎的公告以獲得最新資訊。"
          ]
        }
      ],
      "source": [
        "# 測試串流、無 function calling 功能\n",
        "for chunk in get_reply(\n",
        "    [{\"role\":\"user\", \"content\":\"2023 金馬獎影帝是誰？\"}],\n",
        "    stream=True):\n",
        "    print(chunk, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgZAPh6uTUJQ"
      },
      "source": [
        "## 歷史紀錄測試\n",
        "\n",
        "chat 是以 get_reply 函式為基礎, 加上對談歷史紀錄的功能, 可以使用 backtrace 設定要記錄的對談組數。\n",
        "\n",
        "```python\n",
        "chat(\n",
        "    sys_msg, # system 角色發言\n",
        "    user_msg, # user 角色發言\n",
        "    stream=False, # 是否啟用串流模式\n",
        "    tools_table=tools_table # 工具函式參考表 (預設是模組內建的參考表)\n",
        ")\n",
        "```\n",
        "一樣可以使用選用的參數：\n",
        "\n",
        "```python\n",
        "model='gpt-3.5-turbo' # 指定模型\n",
        "debug=False # 是否要顯示除錯訊息, 包含訊息串列內容\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYFYP1YIUkS4",
        "outputId": "078debad-4075-4dc6-f222-3895554d1e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "嘗試叫用：google_res(**{'user_msg': '2023 金馬獎 最佳女配角'})\n",
            "2023年金馬獎最佳女配角是方志友，她憑藉在電影《本日公休》中的表演獲得該獎項。"
          ]
        }
      ],
      "source": [
        "for chunk in chat(\n",
        "    '小助理',                   # system 角色發言\n",
        "    '2023 金馬獎最佳女配角是誰？', # user 角色發言\n",
        "    True):                     # 使用串流模式\n",
        "    print(chunk, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPB1ONTSVGDh"
      },
      "source": [
        "底下會因為有歷史紀錄而影響建議的搜尋關鍵字："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0EXetr8U1-Z",
        "outputId": "c62691aa-65db-4e2d-b1a6-98e4614d5d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "嘗試叫用：google_res(**{'user_msg': '2022金馬獎最佳女配角'})\n",
            "2022年金馬獎最佳女配角得主是林詹珍妹，她因在電影《哈勇家》中的表演而獲此殊榮。"
          ]
        }
      ],
      "source": [
        "for chunk in chat(\n",
        "    '小助理',                 # system 角色發言\n",
        "    '那 2022 呢？',           # user 角色發言 (會延續對答脈絡)\n",
        "    True):                   # 使用串流模式\n",
        "    print(chunk, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHG1e0UbYvlX"
      },
      "source": [
        "chat 會使用模組內預設的 func_table, 如果不想啟用, 可以加讓 func_table 參數值 None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSk0vWjCV9Dw",
        "outputId": "2050d72c-923a-4eaf-a07d-85b129dd118e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "您好！看起来您只提供了一个年份 \"2021\" 但没有提供具体的问题或者背景信息。如果您需要关于2021年的信息，比如历史事件、科技发展、文化动态等，请提供更多的上下文或者具体问题，我将很乐意为您提供相关信息或者解答疑问。"
          ]
        }
      ],
      "source": [
        "for chunk in chat(\n",
        "    '小助理',               # system 角色發言\n",
        "    '那 2021 呢？',         # user 角色發言\n",
        "    True,                  # 串流模式\n",
        "    None):                 # 不使用工具函式參考表 (因此不會搜尋)\n",
        "    print(chunk, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkWkIyA4VPNU"
      },
      "source": [
        "## 連續交談測試\n",
        "\n",
        "以下是使用 chat 設計的聊天程式："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rR4R1uOuLhx",
        "outputId": "f8b7333e-7911-4b3e-deaa-9fef0bc7a176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "你希望ㄟ唉扮演：\n",
            "\n",
            "你說：2022 金馬獎影后是誰？他執導的電影有哪些？\n",
            "使用繁體中文的小助理：嘗試叫用：google_res(**{'user_msg': '2022金馬獎影後'})\n",
            "嘗試叫用：google_res(**{'user_msg': '張艇姊導演的電影'})\n",
            "2022年的金馬獎影后是張艾嘉，她以電影《燈火闌珊》奪得該獎項。\n",
            "\n",
            "張艾嘉曾執導的電影包括《相愛相親》。由於提供的信息有限，如果您想了解更多關於張艾嘉執導的電影列表，可能需要更進一步的搜索或查詢。\n",
            "\n",
            "你說：\n"
          ]
        }
      ],
      "source": [
        "empty_history()\n",
        "sys_msg = input(\"你希望ㄟ唉扮演：\")\n",
        "if not sys_msg.strip(): sys_msg = '使用繁體中文的小助理'\n",
        "print()\n",
        "while True:\n",
        "    msg = input(\"你說：\")\n",
        "    if not msg.strip(): break\n",
        "    print(f\"{sys_msg}：\", end = \"\")\n",
        "    for reply in chat(sys_msg, msg,\n",
        "                      stream=True,\n",
        "                      debug=True,\n",
        "                      model='gpt-4-1106-preview',\n",
        "                      ):\n",
        "        print(reply, end = \"\")\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y8v2zZQzIpC"
      },
      "source": [
        "## 新增工具函式\n",
        "\n",
        "以文字生圖為例"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbkO6IE_VkEn"
      },
      "source": [
        "用 Image API 設計一個文生圖的工具函式："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge1xqcrCBeWd"
      },
      "outputs": [],
      "source": [
        "def txt_to_img_url(prompt):\n",
        "    response = openai.images.generate(\n",
        "        prompt=prompt,\n",
        "        n=1,\n",
        "        size='1024x1024',\n",
        "        style='vivid',\n",
        "        quality='hd'\n",
        "    )\n",
        "    return response.data[0].url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14aHGxcmVoAG"
      },
      "source": [
        "在工具函式表中新增項目, 生圖後不需要再送回給 AI 處理, 所以 chain 項目設為 False："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh0CFGhiC07Y"
      },
      "outputs": [],
      "source": [
        "tools_table.append(\n",
        "    {                    # 每個元素代表一個函式\n",
        "        \"chain\": False,  # 生圖後不需要傳回給 API\n",
        "        \"func\": txt_to_img_url,\n",
        "        \"spec\": {        # function calling 需要的函式規格\n",
        "            'type': 'function',\n",
        "            'function': {\n",
        "                \"name\": \"txt_to_img_url\",\n",
        "                \"description\": \"可由文字生圖並傳回圖像網址\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"prompt\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"描述要產生圖像內容的文字\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"prompt\"],\n",
        "                },\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools_table.pop()\n",
        "len(tools_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPQ647RRflKk",
        "outputId": "1389fc19-3ba4-47ae-eef7-43c79deacadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIEEJYlYV-cS"
      },
      "source": [
        "測試看看是不是可以正確生圖？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q42dWiLwDvNp",
        "outputId": "50728f7e-b77c-4fc5-b304-de06a514a9b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "嘗試叫用：txt_to_img_url(**{'prompt': 'sunset with dolphin jumping out of the sea'})\n",
            "https://oaidalleapiprodscus.blob.core.windows.net/private/org-TnN5jDJWh2Gbe6gZ6C11q1fl/user-hwS8wMY6Z8ZzjiE3tcFcl4mM/img-4VnFT09UiHTJ3bEXnUmj4cOH.png?st=2023-12-05T04%3A41%3A57Z&se=2023-12-05T06%3A41%3A57Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-04T23%3A04%3A53Z&ske=2023-12-05T23%3A04%3A53Z&sks=b&skv=2021-08-06&sig=KiMHVpzS%2B3FY55ZXz1Ze/A%2BwZh3IxAvEghrsb9kvZu8%3D\n"
          ]
        }
      ],
      "source": [
        "for chunk in chat('小助理', '我想要夕陽下海豚躍出海面的圖像', True):\n",
        "    print(chunk)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}